{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data_fixing import format_and_label_data, format_image\n",
    "from train_model import create_CNN_model,CNN_fit_train,CNN_accuracy,load_CNN_model,CNN_one_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize and greyscale images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 00000114.png, invalid shape: (128, 128)\n",
      "Skipping 00000190.png, invalid shape: (128, 128)\n",
      "Skipping 00000009.png, invalid shape: (128, 128)\n",
      "Skipping 00000021.png, invalid shape: (128, 128)\n",
      "Skipping 00000061.png, invalid shape: (128, 128)\n",
      "Skipping 00000078.png, invalid shape: (128, 128)\n",
      "Skipping 00000172.png, invalid shape: (128, 128)\n",
      "Skipping 59bef3942b6041b3a6e0526100264536.jpg, invalid shape: (128, 128)\n"
     ]
    }
   ],
   "source": [
    "images_labs = format_and_label_data('../images/dataset', 128, False)\n",
    "\n",
    "image_data = images_labs[0]\n",
    "labels = images_labs[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a image to check it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(847, 128, 128, 3)\n",
      "(847,)\n"
     ]
    }
   ],
   "source": [
    "img = image_data[0].reshape(128, 128,3)\n",
    "img_pillow = Image.fromarray(img)\n",
    "img_pillow.show()\n",
    "\n",
    "print(image_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image_data, labels, test_size=0.3, random_state=420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\DrawEmAll\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.4671 - loss: 2.7727\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62353, saving model to ./models/best_model_func.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 278ms/step - accuracy: 0.4706 - loss: 2.7193 - val_accuracy: 0.6235 - val_loss: 0.6091\n",
      "Epoch 2/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.7438 - loss: 0.5653\n",
      "Epoch 2: val_accuracy improved from 0.62353 to 0.93333, saving model to ./models/best_model_func.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 253ms/step - accuracy: 0.7467 - loss: 0.5598 - val_accuracy: 0.9333 - val_loss: 0.2717\n",
      "Epoch 3/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.9078 - loss: 0.2606\n",
      "Epoch 3: val_accuracy improved from 0.93333 to 0.96078, saving model to ./models/best_model_func.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 253ms/step - accuracy: 0.9087 - loss: 0.2583 - val_accuracy: 0.9608 - val_loss: 0.2427\n",
      "Epoch 4/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9292 - loss: 0.1705\n",
      "Epoch 4: val_accuracy improved from 0.96078 to 0.97647, saving model to ./models/best_model_func.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 248ms/step - accuracy: 0.9298 - loss: 0.1699 - val_accuracy: 0.9765 - val_loss: 0.1721\n",
      "Epoch 5/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9484 - loss: 0.1581\n",
      "Epoch 5: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 241ms/step - accuracy: 0.9487 - loss: 0.1574 - val_accuracy: 0.9725 - val_loss: 0.1819\n",
      "Epoch 6/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.9756 - loss: 0.0875\n",
      "Epoch 6: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 237ms/step - accuracy: 0.9757 - loss: 0.0870 - val_accuracy: 0.9725 - val_loss: 0.1814\n",
      "Epoch 7/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9718 - loss: 0.0680\n",
      "Epoch 7: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 248ms/step - accuracy: 0.9722 - loss: 0.0677 - val_accuracy: 0.9490 - val_loss: 0.2550\n",
      "Epoch 8/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9730 - loss: 0.0717\n",
      "Epoch 8: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 255ms/step - accuracy: 0.9731 - loss: 0.0713 - val_accuracy: 0.9686 - val_loss: 0.1584\n",
      "Epoch 9/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9681 - loss: 0.1030\n",
      "Epoch 9: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 253ms/step - accuracy: 0.9676 - loss: 0.1045 - val_accuracy: 0.9686 - val_loss: 0.2153\n",
      "Epoch 10/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.9844 - loss: 0.0597\n",
      "Epoch 10: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 236ms/step - accuracy: 0.9844 - loss: 0.0597 - val_accuracy: 0.9765 - val_loss: 0.1763\n",
      "Epoch 11/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9880 - loss: 0.0329\n",
      "Epoch 11: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 243ms/step - accuracy: 0.9881 - loss: 0.0331 - val_accuracy: 0.9490 - val_loss: 0.2965\n",
      "Epoch 12/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.9769 - loss: 0.0717\n",
      "Epoch 12: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 236ms/step - accuracy: 0.9772 - loss: 0.0706 - val_accuracy: 0.9686 - val_loss: 0.1729\n",
      "Epoch 13/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9985 - loss: 0.0140\n",
      "Epoch 13: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 280ms/step - accuracy: 0.9984 - loss: 0.0142 - val_accuracy: 0.9765 - val_loss: 0.1968\n",
      "Epoch 14/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.9908 - loss: 0.0221\n",
      "Epoch 14: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 243ms/step - accuracy: 0.9906 - loss: 0.0223 - val_accuracy: 0.9765 - val_loss: 0.1732\n",
      "Epoch 15/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9880 - loss: 0.0312\n",
      "Epoch 15: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 279ms/step - accuracy: 0.9880 - loss: 0.0312 - val_accuracy: 0.9686 - val_loss: 0.2665\n",
      "Epoch 16/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9972 - loss: 0.0189\n",
      "Epoch 16: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - accuracy: 0.9971 - loss: 0.0189 - val_accuracy: 0.9725 - val_loss: 0.2596\n",
      "Epoch 17/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.9988 - loss: 0.0080\n",
      "Epoch 17: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 306ms/step - accuracy: 0.9985 - loss: 0.0085 - val_accuracy: 0.9765 - val_loss: 0.2115\n",
      "Epoch 18/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.9926 - loss: 0.0176\n",
      "Epoch 18: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 249ms/step - accuracy: 0.9925 - loss: 0.0177 - val_accuracy: 0.9686 - val_loss: 0.2689\n",
      "Epoch 19/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.9867 - loss: 0.0282\n",
      "Epoch 19: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 251ms/step - accuracy: 0.9866 - loss: 0.0284 - val_accuracy: 0.9725 - val_loss: 0.1907\n",
      "Epoch 20/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.9756 - loss: 0.0558\n",
      "Epoch 20: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 232ms/step - accuracy: 0.9756 - loss: 0.0555 - val_accuracy: 0.9765 - val_loss: 0.1576\n",
      "Epoch 21/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9839 - loss: 0.0577\n",
      "Epoch 21: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 251ms/step - accuracy: 0.9840 - loss: 0.0578 - val_accuracy: 0.9765 - val_loss: 0.2013\n",
      "Epoch 22/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9944 - loss: 0.0252\n",
      "Epoch 22: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 243ms/step - accuracy: 0.9945 - loss: 0.0248 - val_accuracy: 0.9725 - val_loss: 0.2893\n",
      "Epoch 23/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9904 - loss: 0.0232\n",
      "Epoch 23: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 260ms/step - accuracy: 0.9905 - loss: 0.0230 - val_accuracy: 0.9686 - val_loss: 0.3138\n",
      "Epoch 24/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.9912 - loss: 0.0199\n",
      "Epoch 24: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 258ms/step - accuracy: 0.9912 - loss: 0.0202 - val_accuracy: 0.9725 - val_loss: 0.2413\n",
      "Epoch 25/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 0.0055\n",
      "Epoch 25: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 267ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9765 - val_loss: 0.2541\n",
      "Epoch 26/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.9918 - loss: 0.0167\n",
      "Epoch 26: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 251ms/step - accuracy: 0.9919 - loss: 0.0165 - val_accuracy: 0.9725 - val_loss: 0.2314\n",
      "Epoch 27/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.9939 - loss: 0.0203\n",
      "Epoch 27: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 234ms/step - accuracy: 0.9937 - loss: 0.0204 - val_accuracy: 0.9765 - val_loss: 0.2208\n",
      "Epoch 28/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.9945 - loss: 0.0248\n",
      "Epoch 28: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 231ms/step - accuracy: 0.9944 - loss: 0.0252 - val_accuracy: 0.9686 - val_loss: 0.3033\n",
      "Epoch 29/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9845 - loss: 0.0634\n",
      "Epoch 29: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 261ms/step - accuracy: 0.9845 - loss: 0.0630 - val_accuracy: 0.9686 - val_loss: 0.3271\n",
      "Epoch 30/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9858 - loss: 0.0330\n",
      "Epoch 30: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 244ms/step - accuracy: 0.9858 - loss: 0.0331 - val_accuracy: 0.9686 - val_loss: 0.2493\n",
      "Epoch 31/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.9818 - loss: 0.0580\n",
      "Epoch 31: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 231ms/step - accuracy: 0.9823 - loss: 0.0566 - val_accuracy: 0.9686 - val_loss: 0.3055\n",
      "Epoch 32/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9875 - loss: 0.0351\n",
      "Epoch 32: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 244ms/step - accuracy: 0.9875 - loss: 0.0352 - val_accuracy: 0.9686 - val_loss: 0.3397\n",
      "Epoch 33/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9880 - loss: 0.0233\n",
      "Epoch 33: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 235ms/step - accuracy: 0.9882 - loss: 0.0228 - val_accuracy: 0.9686 - val_loss: 0.2354\n",
      "Epoch 34/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.9934 - loss: 0.0164\n",
      "Epoch 34: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 270ms/step - accuracy: 0.9935 - loss: 0.0162 - val_accuracy: 0.9686 - val_loss: 0.2500\n",
      "Epoch 35/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9980 - loss: 0.0059\n",
      "Epoch 35: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 247ms/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.9725 - val_loss: 0.2668\n",
      "Epoch 36/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9985 - loss: 0.0088\n",
      "Epoch 36: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 268ms/step - accuracy: 0.9984 - loss: 0.0091 - val_accuracy: 0.9765 - val_loss: 0.4077\n",
      "Epoch 37/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9899 - loss: 0.0563\n",
      "Epoch 37: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 263ms/step - accuracy: 0.9898 - loss: 0.0574 - val_accuracy: 0.9686 - val_loss: 0.2198\n",
      "Epoch 38/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9885 - loss: 0.0489\n",
      "Epoch 38: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 282ms/step - accuracy: 0.9884 - loss: 0.0488 - val_accuracy: 0.9765 - val_loss: 0.1748\n",
      "Epoch 39/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9908 - loss: 0.0348\n",
      "Epoch 39: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 259ms/step - accuracy: 0.9907 - loss: 0.0345 - val_accuracy: 0.9412 - val_loss: 0.3160\n",
      "Epoch 40/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9954 - loss: 0.0175\n",
      "Epoch 40: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 248ms/step - accuracy: 0.9952 - loss: 0.0178 - val_accuracy: 0.9373 - val_loss: 0.2771\n",
      "Epoch 41/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9934 - loss: 0.0287\n",
      "Epoch 41: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 246ms/step - accuracy: 0.9933 - loss: 0.0288 - val_accuracy: 0.9529 - val_loss: 0.2340\n",
      "Epoch 42/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9996 - loss: 0.0082\n",
      "Epoch 42: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 248ms/step - accuracy: 0.9996 - loss: 0.0082 - val_accuracy: 0.9333 - val_loss: 0.3693\n",
      "Epoch 43/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9958 - loss: 0.0192\n",
      "Epoch 43: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 253ms/step - accuracy: 0.9958 - loss: 0.0191 - val_accuracy: 0.9373 - val_loss: 0.3331\n",
      "Epoch 44/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9915 - loss: 0.0370\n",
      "Epoch 44: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 262ms/step - accuracy: 0.9916 - loss: 0.0366 - val_accuracy: 0.9725 - val_loss: 0.1939\n",
      "Epoch 45/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9936 - loss: 0.0300\n",
      "Epoch 45: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 294ms/step - accuracy: 0.9936 - loss: 0.0300 - val_accuracy: 0.9686 - val_loss: 0.2023\n",
      "Epoch 46/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9975 - loss: 0.0237\n",
      "Epoch 46: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 284ms/step - accuracy: 0.9972 - loss: 0.0243 - val_accuracy: 0.9569 - val_loss: 0.2194\n",
      "Epoch 47/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9911 - loss: 0.0888\n",
      "Epoch 47: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 265ms/step - accuracy: 0.9909 - loss: 0.0879 - val_accuracy: 0.9647 - val_loss: 0.2374\n",
      "Epoch 48/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.9813 - loss: 0.0457\n",
      "Epoch 48: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 257ms/step - accuracy: 0.9816 - loss: 0.0460 - val_accuracy: 0.8471 - val_loss: 1.4893\n",
      "Epoch 49/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9766 - loss: 0.0717\n",
      "Epoch 49: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 254ms/step - accuracy: 0.9769 - loss: 0.0720 - val_accuracy: 0.8902 - val_loss: 0.4185\n",
      "Epoch 50/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.9890 - loss: 0.0284\n",
      "Epoch 50: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 234ms/step - accuracy: 0.9887 - loss: 0.0295 - val_accuracy: 0.8824 - val_loss: 0.9574\n",
      "Epoch 51/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9677 - loss: 0.1394\n",
      "Epoch 51: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 253ms/step - accuracy: 0.9679 - loss: 0.1379 - val_accuracy: 0.9686 - val_loss: 0.2174\n",
      "Epoch 52/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9793 - loss: 0.0478\n",
      "Epoch 52: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 250ms/step - accuracy: 0.9796 - loss: 0.0477 - val_accuracy: 0.9608 - val_loss: 0.1786\n",
      "Epoch 53/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.9794 - loss: 0.0555\n",
      "Epoch 53: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 269ms/step - accuracy: 0.9794 - loss: 0.0573 - val_accuracy: 0.9216 - val_loss: 0.3555\n",
      "Epoch 54/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.9765 - loss: 0.0783\n",
      "Epoch 54: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 254ms/step - accuracy: 0.9768 - loss: 0.0772 - val_accuracy: 0.9647 - val_loss: 0.1815\n",
      "Epoch 55/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9926 - loss: 0.0138\n",
      "Epoch 55: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 260ms/step - accuracy: 0.9928 - loss: 0.0137 - val_accuracy: 0.9569 - val_loss: 0.2160\n",
      "Epoch 56/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0050\n",
      "Epoch 56: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 269ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9686 - val_loss: 0.2271\n",
      "Epoch 57/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9994 - loss: 0.0047\n",
      "Epoch 57: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 239ms/step - accuracy: 0.9993 - loss: 0.0050 - val_accuracy: 0.9686 - val_loss: 0.2942\n",
      "Epoch 58/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9999 - loss: 0.0086\n",
      "Epoch 58: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 215ms/step - accuracy: 0.9998 - loss: 0.0094 - val_accuracy: 0.9608 - val_loss: 0.3727\n",
      "Epoch 59/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.9986 - loss: 0.0061\n",
      "Epoch 59: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 218ms/step - accuracy: 0.9985 - loss: 0.0061 - val_accuracy: 0.9686 - val_loss: 0.2852\n",
      "Epoch 60/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.9934 - loss: 0.0109\n",
      "Epoch 60: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 227ms/step - accuracy: 0.9936 - loss: 0.0107 - val_accuracy: 0.9725 - val_loss: 0.3214\n",
      "Epoch 61/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9945 - loss: 0.0106\n",
      "Epoch 61: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - accuracy: 0.9947 - loss: 0.0104 - val_accuracy: 0.9725 - val_loss: 0.3512\n",
      "Epoch 62/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 62: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9725 - val_loss: 0.3852\n",
      "Epoch 63/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9991 - loss: 0.0030\n",
      "Epoch 63: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 244ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9725 - val_loss: 0.3693\n",
      "Epoch 64/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9976 - loss: 0.0042\n",
      "Epoch 64: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 237ms/step - accuracy: 0.9974 - loss: 0.0043 - val_accuracy: 0.9647 - val_loss: 0.3811\n",
      "Epoch 65/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.9939 - loss: 0.0156\n",
      "Epoch 65: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - accuracy: 0.9939 - loss: 0.0157 - val_accuracy: 0.9451 - val_loss: 0.5720\n",
      "Epoch 66/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 66: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 215ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9686 - val_loss: 0.4645\n",
      "Epoch 67/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.9942 - loss: 0.0190\n",
      "Epoch 67: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 226ms/step - accuracy: 0.9942 - loss: 0.0189 - val_accuracy: 0.9608 - val_loss: 0.6942\n",
      "Epoch 68/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9995 - loss: 0.0021\n",
      "Epoch 68: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 241ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9647 - val_loss: 0.6673\n",
      "Epoch 69/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.9978 - loss: 0.0033\n",
      "Epoch 69: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 228ms/step - accuracy: 0.9978 - loss: 0.0035 - val_accuracy: 0.9647 - val_loss: 0.6221\n",
      "Epoch 70/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.9990 - loss: 0.0030\n",
      "Epoch 70: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 222ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.9686 - val_loss: 0.6079\n",
      "Epoch 71/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9964 - loss: 0.0054\n",
      "Epoch 71: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 233ms/step - accuracy: 0.9965 - loss: 0.0054 - val_accuracy: 0.9686 - val_loss: 0.6000\n",
      "Epoch 72/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 72: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 220ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9725 - val_loss: 0.5635\n",
      "Epoch 73/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0010\n",
      "Epoch 73: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9725 - val_loss: 0.5992\n",
      "Epoch 74/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9990 - loss: 0.0016\n",
      "Epoch 74: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 242ms/step - accuracy: 0.9989 - loss: 0.0016 - val_accuracy: 0.9725 - val_loss: 0.6121\n",
      "Epoch 75/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 1.0000 - loss: 6.3145e-04\n",
      "Epoch 75: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 234ms/step - accuracy: 1.0000 - loss: 6.2114e-04 - val_accuracy: 0.9686 - val_loss: 0.5961\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = create_CNN_model(dropout=0.45,grayscale=False,image_size=128)\n",
    "\n",
    "model = CNN_fit_train(model, X_train,y_train,X_test,y_test,75,32, './models/best_model_func.keras')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test on hand drawn images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_data_and_lab = format_and_label_data('../images/Hand_Drawn')\n",
    "hand_data = hand_data_and_lab[0]\n",
    "labels = hand_data_and_lab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = hand_data[0].reshape(128,128 ,3)\n",
    "img_pillow = Image.fromarray(img)\n",
    "img_pillow.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model  = load_CNN_model('./models/best_model_func.keras')\n",
    "acc = CNN_accuracy(model, hand_data, labels)\n",
    "print(acc) \n",
    "#note accuracy is low because of the non-colored drawings being performed poorly on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 30 epochs for all the colored ones to be guessed correctly..., non colored defaults to squirtle\n",
    "\n",
    "Using data gen now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\DrawEmAll\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\DrawEmAll\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.4494 - loss: 2.6105\n",
      "Epoch 1: val_accuracy improved from -inf to 0.80392, saving model to ./models/best_model_func.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 336ms/step - accuracy: 0.4551 - loss: 2.5575 - val_accuracy: 0.8039 - val_loss: 0.4196\n",
      "Epoch 2/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.8530 - loss: 0.4975\n",
      "Epoch 2: val_accuracy did not improve from 0.80392\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 282ms/step - accuracy: 0.8533 - loss: 0.5023 - val_accuracy: 0.7843 - val_loss: 0.5358\n",
      "Epoch 3/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.8768 - loss: 0.3729\n",
      "Epoch 3: val_accuracy improved from 0.80392 to 0.81569, saving model to ./models/best_model_func.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 629ms/step - accuracy: 0.8777 - loss: 0.3710 - val_accuracy: 0.8157 - val_loss: 0.5138\n",
      "Epoch 4/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.9123 - loss: 0.2393\n",
      "Epoch 4: val_accuracy improved from 0.81569 to 0.87843, saving model to ./models/best_model_func.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 322ms/step - accuracy: 0.9127 - loss: 0.2398 - val_accuracy: 0.8784 - val_loss: 0.3520\n",
      "Epoch 5/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9573 - loss: 0.1597\n",
      "Epoch 5: val_accuracy did not improve from 0.87843\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 286ms/step - accuracy: 0.9569 - loss: 0.1611 - val_accuracy: 0.8510 - val_loss: 0.4335\n",
      "Epoch 6/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.9305 - loss: 0.2232\n",
      "Epoch 6: val_accuracy improved from 0.87843 to 0.94510, saving model to ./models/best_model_func.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 257ms/step - accuracy: 0.9307 - loss: 0.2223 - val_accuracy: 0.9451 - val_loss: 0.2398\n",
      "Epoch 7/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.9681 - loss: 0.1874\n",
      "Epoch 7: val_accuracy did not improve from 0.94510\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 259ms/step - accuracy: 0.9675 - loss: 0.1863 - val_accuracy: 0.8275 - val_loss: 0.4585\n",
      "Epoch 8/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.9119 - loss: 0.2831\n",
      "Epoch 8: val_accuracy improved from 0.94510 to 0.96863, saving model to ./models/best_model_func.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9125 - loss: 0.2811 - val_accuracy: 0.9686 - val_loss: 0.1472\n",
      "Epoch 9/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.9616 - loss: 0.1349\n",
      "Epoch 9: val_accuracy did not improve from 0.96863\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 327ms/step - accuracy: 0.9613 - loss: 0.1354 - val_accuracy: 0.9490 - val_loss: 0.2608\n",
      "Epoch 10/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.9466 - loss: 0.1694\n",
      "Epoch 10: val_accuracy did not improve from 0.96863\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 326ms/step - accuracy: 0.9466 - loss: 0.1693 - val_accuracy: 0.9608 - val_loss: 0.1367\n",
      "Epoch 11/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.9598 - loss: 0.1459\n",
      "Epoch 11: val_accuracy did not improve from 0.96863\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 317ms/step - accuracy: 0.9599 - loss: 0.1451 - val_accuracy: 0.9020 - val_loss: 0.3790\n",
      "Epoch 12/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.9632 - loss: 0.1600\n",
      "Epoch 12: val_accuracy did not improve from 0.96863\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 308ms/step - accuracy: 0.9626 - loss: 0.1617 - val_accuracy: 0.9608 - val_loss: 0.1502\n",
      "Epoch 13/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.9629 - loss: 0.1086\n",
      "Epoch 13: val_accuracy improved from 0.96863 to 0.97255, saving model to ./models/best_model_func.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - accuracy: 0.9626 - loss: 0.1104 - val_accuracy: 0.9725 - val_loss: 0.1207\n",
      "Epoch 14/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9608 - loss: 0.1143\n",
      "Epoch 14: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 307ms/step - accuracy: 0.9601 - loss: 0.1192 - val_accuracy: 0.9412 - val_loss: 0.1992\n",
      "Epoch 15/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.9312 - loss: 0.1917\n",
      "Epoch 15: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 307ms/step - accuracy: 0.9310 - loss: 0.1927 - val_accuracy: 0.9373 - val_loss: 0.2222\n",
      "Epoch 16/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.9091 - loss: 0.2060\n",
      "Epoch 16: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 306ms/step - accuracy: 0.9095 - loss: 0.2047 - val_accuracy: 0.8902 - val_loss: 0.2457\n",
      "Epoch 17/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.9535 - loss: 0.1886\n",
      "Epoch 17: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 321ms/step - accuracy: 0.9531 - loss: 0.1904 - val_accuracy: 0.9373 - val_loss: 0.1831\n",
      "Epoch 18/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.9378 - loss: 0.1480\n",
      "Epoch 18: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 389ms/step - accuracy: 0.9383 - loss: 0.1476 - val_accuracy: 0.9255 - val_loss: 0.2338\n",
      "Epoch 19/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 0.9261 - loss: 0.1902\n",
      "Epoch 19: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 390ms/step - accuracy: 0.9271 - loss: 0.1879 - val_accuracy: 0.9725 - val_loss: 0.1006\n",
      "Epoch 20/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.9600 - loss: 0.1365\n",
      "Epoch 20: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 304ms/step - accuracy: 0.9598 - loss: 0.1370 - val_accuracy: 0.9647 - val_loss: 0.0985\n",
      "Epoch 21/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9371 - loss: 0.1764\n",
      "Epoch 21: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 308ms/step - accuracy: 0.9374 - loss: 0.1765 - val_accuracy: 0.9529 - val_loss: 0.1434\n",
      "Epoch 22/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.9518 - loss: 0.1818\n",
      "Epoch 22: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9522 - loss: 0.1795 - val_accuracy: 0.9294 - val_loss: 0.2457\n",
      "Epoch 23/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.9868 - loss: 0.0755\n",
      "Epoch 23: val_accuracy improved from 0.97255 to 0.97647, saving model to ./models/best_model_func.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9867 - loss: 0.0760 - val_accuracy: 0.9765 - val_loss: 0.1222\n",
      "Epoch 24/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.9487 - loss: 0.1252\n",
      "Epoch 24: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 401ms/step - accuracy: 0.9490 - loss: 0.1246 - val_accuracy: 0.9529 - val_loss: 0.2236\n",
      "Epoch 25/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.9623 - loss: 0.1404\n",
      "Epoch 25: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.9619 - loss: 0.1403 - val_accuracy: 0.8980 - val_loss: 0.3748\n",
      "Epoch 26/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.9444 - loss: 0.1817\n",
      "Epoch 26: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 323ms/step - accuracy: 0.9445 - loss: 0.1811 - val_accuracy: 0.9137 - val_loss: 0.3239\n",
      "Epoch 27/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.9637 - loss: 0.1248\n",
      "Epoch 27: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9632 - loss: 0.1265 - val_accuracy: 0.9569 - val_loss: 0.1786\n",
      "Epoch 28/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9597 - loss: 0.1262\n",
      "Epoch 28: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 323ms/step - accuracy: 0.9592 - loss: 0.1267 - val_accuracy: 0.9569 - val_loss: 0.1696\n",
      "Epoch 29/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.9655 - loss: 0.1081\n",
      "Epoch 29: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 321ms/step - accuracy: 0.9652 - loss: 0.1088 - val_accuracy: 0.9451 - val_loss: 0.2191\n",
      "Epoch 30/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.9621 - loss: 0.1180\n",
      "Epoch 30: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 355ms/step - accuracy: 0.9621 - loss: 0.1175 - val_accuracy: 0.9412 - val_loss: 0.1849\n",
      "Epoch 31/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.9566 - loss: 0.1131\n",
      "Epoch 31: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - accuracy: 0.9568 - loss: 0.1127 - val_accuracy: 0.9373 - val_loss: 0.2029\n",
      "Epoch 32/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.9754 - loss: 0.0938\n",
      "Epoch 32: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9752 - loss: 0.0945 - val_accuracy: 0.9490 - val_loss: 0.1488\n",
      "Epoch 33/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9376 - loss: 0.1810\n",
      "Epoch 33: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 308ms/step - accuracy: 0.9384 - loss: 0.1791 - val_accuracy: 0.9569 - val_loss: 0.1439\n",
      "Epoch 34/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.9753 - loss: 0.0864\n",
      "Epoch 34: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 312ms/step - accuracy: 0.9750 - loss: 0.0875 - val_accuracy: 0.9569 - val_loss: 0.1657\n",
      "Epoch 35/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.9595 - loss: 0.1072\n",
      "Epoch 35: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 315ms/step - accuracy: 0.9597 - loss: 0.1069 - val_accuracy: 0.9412 - val_loss: 0.1380\n",
      "Epoch 36/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.9738 - loss: 0.0686\n",
      "Epoch 36: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.9736 - loss: 0.0685 - val_accuracy: 0.9647 - val_loss: 0.1445\n",
      "Epoch 37/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.9668 - loss: 0.1043\n",
      "Epoch 37: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 294ms/step - accuracy: 0.9666 - loss: 0.1046 - val_accuracy: 0.9725 - val_loss: 0.1121\n",
      "Epoch 38/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.9790 - loss: 0.0800\n",
      "Epoch 38: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - accuracy: 0.9789 - loss: 0.0801 - val_accuracy: 0.9725 - val_loss: 0.1173\n",
      "Epoch 39/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.9757 - loss: 0.0567\n",
      "Epoch 39: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 295ms/step - accuracy: 0.9757 - loss: 0.0567 - val_accuracy: 0.9647 - val_loss: 0.1226\n",
      "Epoch 40/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9795 - loss: 0.0550\n",
      "Epoch 40: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 255ms/step - accuracy: 0.9794 - loss: 0.0560 - val_accuracy: 0.9647 - val_loss: 0.1275\n",
      "Epoch 41/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9917 - loss: 0.0462\n",
      "Epoch 41: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - accuracy: 0.9913 - loss: 0.0467 - val_accuracy: 0.9647 - val_loss: 0.1465\n",
      "Epoch 42/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9817 - loss: 0.0613\n",
      "Epoch 42: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - accuracy: 0.9814 - loss: 0.0629 - val_accuracy: 0.9647 - val_loss: 0.1244\n",
      "Epoch 43/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9720 - loss: 0.0792\n",
      "Epoch 43: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 244ms/step - accuracy: 0.9718 - loss: 0.0798 - val_accuracy: 0.9569 - val_loss: 0.1516\n",
      "Epoch 44/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9842 - loss: 0.0524\n",
      "Epoch 44: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 245ms/step - accuracy: 0.9842 - loss: 0.0526 - val_accuracy: 0.9569 - val_loss: 0.1603\n",
      "Epoch 45/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.9845 - loss: 0.0414\n",
      "Epoch 45: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 312ms/step - accuracy: 0.9846 - loss: 0.0414 - val_accuracy: 0.9686 - val_loss: 0.1589\n",
      "Epoch 46/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9748 - loss: 0.0544\n",
      "Epoch 46: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 273ms/step - accuracy: 0.9751 - loss: 0.0543 - val_accuracy: 0.9686 - val_loss: 0.1343\n",
      "Epoch 47/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9866 - loss: 0.0341\n",
      "Epoch 47: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 256ms/step - accuracy: 0.9865 - loss: 0.0345 - val_accuracy: 0.9608 - val_loss: 0.1633\n",
      "Epoch 48/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9835 - loss: 0.0693\n",
      "Epoch 48: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 260ms/step - accuracy: 0.9835 - loss: 0.0698 - val_accuracy: 0.8196 - val_loss: 0.7164\n",
      "Epoch 49/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9684 - loss: 0.1076\n",
      "Epoch 49: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 267ms/step - accuracy: 0.9683 - loss: 0.1074 - val_accuracy: 0.9529 - val_loss: 0.2124\n",
      "Epoch 50/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9835 - loss: 0.0783\n",
      "Epoch 50: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - accuracy: 0.9832 - loss: 0.0786 - val_accuracy: 0.9490 - val_loss: 0.1855\n",
      "Epoch 51/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.9640 - loss: 0.0780\n",
      "Epoch 51: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 257ms/step - accuracy: 0.9642 - loss: 0.0777 - val_accuracy: 0.9647 - val_loss: 0.1414\n",
      "Epoch 52/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9622 - loss: 0.1212\n",
      "Epoch 52: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 259ms/step - accuracy: 0.9620 - loss: 0.1227 - val_accuracy: 0.9490 - val_loss: 0.1433\n",
      "Epoch 53/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.9672 - loss: 0.1097\n",
      "Epoch 53: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 247ms/step - accuracy: 0.9670 - loss: 0.1103 - val_accuracy: 0.9608 - val_loss: 0.2242\n",
      "Epoch 54/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9734 - loss: 0.0722\n",
      "Epoch 54: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 250ms/step - accuracy: 0.9735 - loss: 0.0724 - val_accuracy: 0.9686 - val_loss: 0.2959\n",
      "Epoch 55/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9752 - loss: 0.0887\n",
      "Epoch 55: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 256ms/step - accuracy: 0.9751 - loss: 0.0899 - val_accuracy: 0.9176 - val_loss: 0.3224\n",
      "Epoch 56/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9682 - loss: 0.0681\n",
      "Epoch 56: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 248ms/step - accuracy: 0.9684 - loss: 0.0680 - val_accuracy: 0.9569 - val_loss: 0.2402\n",
      "Epoch 57/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9667 - loss: 0.0887\n",
      "Epoch 57: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 239ms/step - accuracy: 0.9670 - loss: 0.0890 - val_accuracy: 0.9529 - val_loss: 0.2042\n",
      "Epoch 58/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9632 - loss: 0.1010\n",
      "Epoch 58: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 264ms/step - accuracy: 0.9632 - loss: 0.1002 - val_accuracy: 0.9647 - val_loss: 0.1981\n",
      "Epoch 59/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9840 - loss: 0.0655\n",
      "Epoch 59: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 249ms/step - accuracy: 0.9837 - loss: 0.0666 - val_accuracy: 0.9686 - val_loss: 0.2433\n",
      "Epoch 60/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.9784 - loss: 0.1064\n",
      "Epoch 60: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 235ms/step - accuracy: 0.9777 - loss: 0.1068 - val_accuracy: 0.9608 - val_loss: 0.3527\n",
      "Epoch 61/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9702 - loss: 0.0858\n",
      "Epoch 61: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 245ms/step - accuracy: 0.9701 - loss: 0.0862 - val_accuracy: 0.9490 - val_loss: 0.2026\n",
      "Epoch 62/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.9705 - loss: 0.1190\n",
      "Epoch 62: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 241ms/step - accuracy: 0.9699 - loss: 0.1189 - val_accuracy: 0.9686 - val_loss: 0.1040\n",
      "Epoch 63/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9850 - loss: 0.0511\n",
      "Epoch 63: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 237ms/step - accuracy: 0.9848 - loss: 0.0517 - val_accuracy: 0.9647 - val_loss: 0.1763\n",
      "Epoch 64/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.9731 - loss: 0.0829\n",
      "Epoch 64: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - accuracy: 0.9732 - loss: 0.0825 - val_accuracy: 0.9569 - val_loss: 0.3173\n",
      "Epoch 65/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.9748 - loss: 0.0494\n",
      "Epoch 65: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 237ms/step - accuracy: 0.9751 - loss: 0.0499 - val_accuracy: 0.9569 - val_loss: 0.2585\n",
      "Epoch 66/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9709 - loss: 0.0603\n",
      "Epoch 66: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 236ms/step - accuracy: 0.9711 - loss: 0.0603 - val_accuracy: 0.9333 - val_loss: 0.2601\n",
      "Epoch 67/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9819 - loss: 0.0535\n",
      "Epoch 67: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 285ms/step - accuracy: 0.9817 - loss: 0.0538 - val_accuracy: 0.9686 - val_loss: 0.2192\n",
      "Epoch 68/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9844 - loss: 0.0450\n",
      "Epoch 68: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 277ms/step - accuracy: 0.9847 - loss: 0.0451 - val_accuracy: 0.9686 - val_loss: 0.2567\n",
      "Epoch 69/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9837 - loss: 0.0408\n",
      "Epoch 69: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 271ms/step - accuracy: 0.9839 - loss: 0.0413 - val_accuracy: 0.9647 - val_loss: 0.2659\n",
      "Epoch 70/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9952 - loss: 0.0184\n",
      "Epoch 70: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 256ms/step - accuracy: 0.9950 - loss: 0.0187 - val_accuracy: 0.9686 - val_loss: 0.2092\n",
      "Epoch 71/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.9827 - loss: 0.0443\n",
      "Epoch 71: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 254ms/step - accuracy: 0.9830 - loss: 0.0434 - val_accuracy: 0.9686 - val_loss: 0.2585\n",
      "Epoch 72/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9886 - loss: 0.0277\n",
      "Epoch 72: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 291ms/step - accuracy: 0.9883 - loss: 0.0287 - val_accuracy: 0.9647 - val_loss: 0.2887\n",
      "Epoch 73/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9769 - loss: 0.0846\n",
      "Epoch 73: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 237ms/step - accuracy: 0.9772 - loss: 0.0832 - val_accuracy: 0.9647 - val_loss: 0.1465\n",
      "Epoch 74/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.9952 - loss: 0.0303\n",
      "Epoch 74: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 230ms/step - accuracy: 0.9949 - loss: 0.0307 - val_accuracy: 0.9686 - val_loss: 0.1792\n",
      "Epoch 75/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.9929 - loss: 0.0276\n",
      "Epoch 75: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 228ms/step - accuracy: 0.9929 - loss: 0.0277 - val_accuracy: 0.9490 - val_loss: 0.2351\n"
     ]
    }
   ],
   "source": [
    "model = create_CNN_model(dropout=0.45,grayscale=False,image_size=128)\n",
    "\n",
    "model = CNN_fit_train(model, X_train,y_train,X_test,y_test,75,32, './models/best_model_func.keras', datagen = True)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "model  = load_CNN_model('./models/best_model_func.keras')\n",
    "acc = CNN_accuracy(model, hand_data, labels)\n",
    "print(acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black and White:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greyscale model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping (001) Bulbasaur (Screenshot).jfif, invalid shape: (128, 128)\n",
      "Skipping 00000000.png, invalid shape: (128, 128)\n",
      "Skipping 00000001.png, invalid shape: (128, 128)\n",
      "Skipping 00000002.png, invalid shape: (128, 128)\n",
      "Skipping 00000003.png, invalid shape: (128, 128)\n",
      "Skipping 00000004.png, invalid shape: (128, 128)\n",
      "Skipping 00000005.png, invalid shape: (128, 128)\n",
      "Skipping 00000006.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000007.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000008.png, invalid shape: (128, 128)\n",
      "Skipping 00000009.png, invalid shape: (128, 128)\n",
      "Skipping 00000010.png, invalid shape: (128, 128)\n",
      "Skipping 00000011.png, invalid shape: (128, 128)\n",
      "Skipping 00000012.png, invalid shape: (128, 128)\n",
      "Skipping 00000013.png, invalid shape: (128, 128)\n",
      "Skipping 00000014.png, invalid shape: (128, 128)\n",
      "Skipping 00000015.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000016.png, invalid shape: (128, 128)\n",
      "Skipping 00000017.png, invalid shape: (128, 128)\n",
      "Skipping 00000018.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000019.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000020.png, invalid shape: (128, 128)\n",
      "Skipping 00000021.png, invalid shape: (128, 128)\n",
      "Skipping 00000022.png, invalid shape: (128, 128)\n",
      "Skipping 00000023.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000024.png, invalid shape: (128, 128)\n",
      "Skipping 00000025.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000026.png, invalid shape: (128, 128)\n",
      "Skipping 00000027.png, invalid shape: (128, 128)\n",
      "Skipping 00000028.png, invalid shape: (128, 128)\n",
      "Skipping 00000029.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000030.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000031.png, invalid shape: (128, 128)\n",
      "Skipping 00000032.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000033.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000034.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000035.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000036.png, invalid shape: (128, 128)\n",
      "Skipping 00000037.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000038.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000040.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000041.png, invalid shape: (128, 128)\n",
      "Skipping 00000042.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000044.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000045.png, invalid shape: (128, 128)\n",
      "Skipping 00000046.png, invalid shape: (128, 128)\n",
      "Skipping 00000047.png, invalid shape: (128, 128)\n",
      "Skipping 00000048.png, invalid shape: (128, 128)\n",
      "Skipping 00000049.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000050.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000051.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000052.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000053.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000055.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000057.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000058.png, invalid shape: (128, 128)\n",
      "Skipping 00000059.png, invalid shape: (128, 128)\n",
      "Skipping 00000060.png, invalid shape: (128, 128)\n",
      "Skipping 00000061.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000062.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000063.png, invalid shape: (128, 128)\n",
      "Skipping 00000065.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000066.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000067.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000068.png, invalid shape: (128, 128)\n",
      "Skipping 00000069.png, invalid shape: (128, 128)\n",
      "Skipping 00000070.png, invalid shape: (128, 128)\n",
      "Skipping 00000072.png, invalid shape: (128, 128)\n",
      "Skipping 00000074.png, invalid shape: (128, 128)\n",
      "Skipping 00000075.png, invalid shape: (128, 128)\n",
      "Skipping 00000076.png, invalid shape: (128, 128)\n",
      "Skipping 00000077.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000078.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000079.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000080.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000081.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000082.png, invalid shape: (128, 128)\n",
      "Skipping 00000083.png, invalid shape: (128, 128)\n",
      "Skipping 00000084.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000085.png, invalid shape: (128, 128)\n",
      "Skipping 00000087.png, invalid shape: (128, 128)\n",
      "Skipping 00000088.png, invalid shape: (128, 128)\n",
      "Skipping 00000089.png, invalid shape: (128, 128)\n",
      "Skipping 00000090.png, invalid shape: (128, 128)\n",
      "Skipping 00000091.png, invalid shape: (128, 128)\n",
      "Skipping 00000092.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000093.png, invalid shape: (128, 128)\n",
      "Skipping 00000094.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000095.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000097.png, invalid shape: (128, 128)\n",
      "Skipping 00000098.png, invalid shape: (128, 128)\n",
      "Skipping 00000099.png, invalid shape: (128, 128)\n",
      "Skipping 00000100.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000101.png, invalid shape: (128, 128)\n",
      "Skipping 00000103.png, invalid shape: (128, 128)\n",
      "Skipping 00000104.png, invalid shape: (128, 128)\n",
      "Skipping 00000105.png, invalid shape: (128, 128)\n",
      "Skipping 00000106.png, invalid shape: (128, 128)\n",
      "Skipping 00000107.png, invalid shape: (128, 128)\n",
      "Skipping 00000108.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000109.png, invalid shape: (128, 128)\n",
      "Skipping 00000110.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000111.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000114.png, invalid shape: (128, 128)\n",
      "Skipping 00000116.png, invalid shape: (128, 128)\n",
      "Skipping 00000117.png, invalid shape: (128, 128)\n",
      "Skipping 00000121.png, invalid shape: (128, 128)\n",
      "Skipping 00000123.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000126.png, invalid shape: (128, 128)\n",
      "Skipping 00000127.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000129.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000131.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000132.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000133.png, invalid shape: (128, 128)\n",
      "Skipping 00000135.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000136.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000137.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000138.png, invalid shape: (128, 128)\n",
      "Skipping 00000141.png, invalid shape: (128, 128)\n",
      "Skipping 00000142.png, invalid shape: (128, 128)\n",
      "Skipping 00000143.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000146.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000149.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000150.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000151.png, invalid shape: (128, 128)\n",
      "Skipping 00000153.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000154.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000155.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000156.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000157.png, invalid shape: (128, 128)\n",
      "Skipping 00000158.png, invalid shape: (128, 128)\n",
      "Skipping 00000160.png, invalid shape: (128, 128)\n",
      "Skipping 00000162.png, invalid shape: (128, 128)\n",
      "Skipping 00000163.png, invalid shape: (128, 128)\n",
      "Skipping 00000164.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000166.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000168.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000169.png, invalid shape: (128, 128)\n",
      "Skipping 00000170.png, invalid shape: (128, 128)\n",
      "Skipping 00000171.png, invalid shape: (128, 128)\n",
      "Skipping 00000173.png, invalid shape: (128, 128)\n",
      "Skipping 00000174.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000175.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000176.png, invalid shape: (128, 128)\n",
      "Skipping 00000177.png, invalid shape: (128, 128)\n",
      "Skipping 00000179.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000180.png, invalid shape: (128, 128)\n",
      "Skipping 00000182.png, invalid shape: (128, 128)\n",
      "Skipping 00000183.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000184.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000185.png, invalid shape: (128, 128)\n",
      "Skipping 00000186.png, invalid shape: (128, 128)\n",
      "Skipping 00000187.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000188.png, invalid shape: (128, 128)\n",
      "Skipping 00000189.png, invalid shape: (128, 128)\n",
      "Skipping 00000190.png, invalid shape: (128, 128)\n",
      "Skipping 00000191.png, invalid shape: (128, 128)\n",
      "Skipping 00000192.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000193.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000195.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000196.png, invalid shape: (128, 128)\n",
      "Skipping 00000197.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000199.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000200.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000201.png, invalid shape: (128, 128)\n",
      "Skipping 00000204.png, invalid shape: (128, 128)\n",
      "Skipping 00000211.png, invalid shape: (128, 128)\n",
      "Skipping 00000214.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000216.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000218.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000221.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000223.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000225.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000227.png, invalid shape: (128, 128)\n",
      "Skipping 00000232.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000233.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000237.png, invalid shape: (128, 128)\n",
      "Skipping 02bafb5a-bfae-4e68-9824-4b6e40c43c7b.jfif, invalid shape: (128, 128)\n",
      "Skipping 09937bd03d6647b98b71b5d4110489c9.jpg, invalid shape: (128, 128)\n",
      "Skipping 0a3a642e700b4153b115e0f645d273f1.jpg, invalid shape: (128, 128)\n",
      "Skipping 0caa4a4284284e0788b98d91260e3858.jpg, invalid shape: (128, 128)\n",
      "Skipping 109a83e831e44d73a36f7f662961832c.jpg, invalid shape: (128, 128)\n",
      "Skipping 1cda95ccc345453b90c46657028cd978.jpg, invalid shape: (128, 128)\n",
      "Skipping 1f42ef8c1eae48f2afab13a807e67970.jpg, invalid shape: (128, 128)\n",
      "Skipping 232f523dcc4a4e919b97fa95444dfbe6.jpg, invalid shape: (128, 128)\n",
      "Skipping 24e2594b0dc14e5895d894b2e636f150.jpg, invalid shape: (128, 128)\n",
      "Skipping 307f8071c6a4441788d4e3eaf3d9d773.jpg, invalid shape: (128, 128)\n",
      "Skipping 34cdbd6ace204143afb0d38fcbed7cc5.jpg, invalid shape: (128, 128)\n",
      "Skipping 4148c76d5e24421eb1172b515269dce6.jpg, invalid shape: (128, 128)\n",
      "Skipping 49cc475b36234ccb87529e2eac142ecd.jpg, invalid shape: (128, 128)\n",
      "Skipping 4d50ac403eb44d71ba9c2d26217b26af.jpg, invalid shape: (128, 128)\n",
      "Skipping 4fbe2ce0f6894dfb9c6813f03c85bf55.jpg, invalid shape: (128, 128)\n",
      "Skipping 5632c9e6a1f844f2b5b08656d93fb36e.jpg, invalid shape: (128, 128)\n",
      "Skipping 5ecb491b17fa45278ced50c25dcecc3f.jpg, invalid shape: (128, 128)\n",
      "Skipping 697a9d3fb69b43f692c3363a5d926b1f.jpg, invalid shape: (128, 128)\n",
      "Skipping 6ed5be2b71814dd8b3e372282b374ddf.jpg, invalid shape: (128, 128)\n",
      "Skipping 734260ff9c1c449d978524a716c8e378.jpg, invalid shape: (128, 128)\n",
      "Skipping 744c813e0ee0420eab1ad3572db9c901.jpg, invalid shape: (128, 128)\n",
      "Skipping 799a00030f4941fda30aa268d174c1c2.jpg, invalid shape: (128, 128)\n",
      "Skipping 7d9f0d694c4e4255b2ab4d78f954ad96.jpg, invalid shape: (128, 128)\n",
      "Skipping 7eb94c12eaab4b7caab6269d44e68726.jpg, invalid shape: (128, 128)\n",
      "Skipping 818bcf41b00c4c58a7f16fcf288e5b1a.jpg, invalid shape: (128, 128)\n",
      "Skipping 84fab3c6980440cea3ae080e165829b6.jpg, invalid shape: (128, 128)\n",
      "Skipping 865a470c5bea4b5dafac4cad972e91fa.jpg, invalid shape: (128, 128)\n",
      "Skipping 8b18f146410a487e96587cca1867bf60.jpg, invalid shape: (128, 128)\n",
      "Skipping 941a3fe752a44319b36873984af0736f.jpg, invalid shape: (128, 128)\n",
      "Skipping 95392cd3-f4ae-4708-b13b-6e3cf680f966.jfif, invalid shape: (128, 128)\n",
      "Skipping 95667f5d-2970-409b-bc4e-938e03d4c2fb.jfif, invalid shape: (128, 128)\n",
      "Skipping 9573aa9a0c354f739be4270e283730cf.jpg, invalid shape: (128, 128)\n",
      "Skipping 972ecc049e20442eaa6627bfae4ad3c8.jpg, invalid shape: (128, 128)\n",
      "Skipping 983ffaa860204dd483e07d54dae85c1d.jpg, invalid shape: (128, 128)\n",
      "Skipping a3cbb796a8594576aff2de5d612ddf9f.jpg, invalid shape: (128, 128)\n",
      "Skipping a6add7027a5442639911b4a2c46af75e.jpg, invalid shape: (128, 128)\n",
      "Skipping a70c2276-06b0-460d-9ed2-01becf652c42.jfif, invalid shape: (128, 128)\n",
      "Skipping aa9b196e27694c9e96df3221bd0dccf9.jpg, invalid shape: (128, 128)\n",
      "Skipping ac9fe1cda0614fae9b7dae05f2a6b3e3.jpg, invalid shape: (128, 128)\n",
      "Skipping b569baa3113d40078326ae3d37e9b658.jpg, invalid shape: (128, 128)\n",
      "Skipping bdeccc2d-50ae-49e5-aeb1-9acde0558581.jfif, invalid shape: (128, 128)\n",
      "Skipping bulbasaur (1).jfif, invalid shape: (128, 128)\n",
      "Skipping Bulbasaur (2).jfif, invalid shape: (128, 128)\n",
      "Skipping bulbasaur (3).jfif, invalid shape: (128, 128)\n",
      "Skipping Bulbasaur Cactus.jfif, invalid shape: (128, 128)\n",
      "Skipping Bulbasaur Logo PNG Vector (SVG) Free Download.jfif, invalid shape: (128, 128)\n",
      "Skipping Bulbasaur! (1).jfif, invalid shape: (128, 128)\n",
      "Skipping Bulbasaur, Pokemon, Artist_ Pearl7.jfif, invalid shape: (128, 128)\n",
      "Skipping Bulbasaur.jfif, invalid shape: (128, 128)\n",
      "Skipping BULBASAUR.jpg, invalid shape: (128, 128)\n",
      "Skipping c4e57436ca6a4a789a56eb880118ebf8.jpg, invalid shape: (128, 128)\n",
      "Skipping c9c697a6cd984bbbb7286c84082ca81d.jpg, invalid shape: (128, 128)\n",
      "Skipping cc4cfa1472244c24a417a504bb035662.jpg, invalid shape: (128, 128)\n",
      "Skipping Cute Bulbasaur!.jfif, invalid shape: (128, 128)\n",
      "Skipping d4fb80d184ad4d578437a27b0e47bbbd.jpg, invalid shape: (128, 128)\n",
      "Skipping download (1).jfif, invalid shape: (128, 128)\n",
      "Skipping download (2).jfif, invalid shape: (128, 128)\n",
      "Skipping download (3).jfif, invalid shape: (128, 128)\n",
      "Skipping download (4).jfif, invalid shape: (128, 128)\n",
      "Skipping download (5).jfif, invalid shape: (128, 128)\n",
      "Skipping download (6).jfif, invalid shape: (128, 128)\n",
      "Skipping download (7).jfif, invalid shape: (128, 128)\n",
      "Skipping download (8).jfif, invalid shape: (128, 128)\n",
      "Skipping download.jfif, invalid shape: (128, 128)\n",
      "Skipping e474267715584c2992faa1fdb2936731.jpg, invalid shape: (128, 128)\n",
      "Skipping e87f21d1ea7e473da0441bfcbca3efce.jpg, invalid shape: (128, 128)\n",
      "Skipping eca4f7fcf5654ff8af71a25798a341bd.jpg, invalid shape: (128, 128)\n",
      "Skipping eed710f5-342d-49f4-ad68-310f5983e735.jfif, invalid shape: (128, 128)\n",
      "Skipping ef1136e7-9209-416f-a823-3de40b787c6d.jfif, invalid shape: (128, 128)\n",
      "Skipping ef68117f55504a29b130dc47c041c06a.jpg, invalid shape: (128, 128)\n",
      "Skipping f4c08f51ea2d4f4e843e168cd0b5dd84.jpg, invalid shape: (128, 128)\n",
      "Skipping ff9150dbde634810ae1e885a343b9dda.jpg, invalid shape: (128, 128)\n",
      "Skipping hyrule in a pokeball.jpg, invalid shape: (128, 128)\n",
      "Skipping Pokemon Gems (@PokemonGems) on X.jfif, invalid shape: (128, 128)\n",
      "Skipping Pokemon_ Bulbasaur by mark331 on DeviantArt.jfif, invalid shape: (128, 128)\n",
      "Skipping pokémon.jfif, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 120704.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 120741.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 120823.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 120845.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 120922.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 120952.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 121041.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 121103.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 121231.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 121257.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 121510.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 122202.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 122218.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 122239.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 122302.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 122328.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 122520.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 122700.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 122940.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 123028.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 123327.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 123429.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 123456.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 123552.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 123630.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 123650.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 123711.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 123829.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 124100.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 124210.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 124241.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 124420.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 124532.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 124849.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 125156.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 125827.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 130019.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 131214.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 131246.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 131932.png, invalid shape: (128, 128)\n",
      "Skipping Screenshot 2024-11-06 132017.png, invalid shape: (128, 128)\n",
      "Skipping Sevi 🌸🌿 (@SeviYummy) on X.jfif, invalid shape: (128, 128)\n",
      "Skipping Sleeping Bulbasaur is so cute.jfif, invalid shape: (128, 128)\n",
      "Skipping Where can I get one__.jfif, invalid shape: (128, 128)\n",
      "Skipping こだ沢 (@Kodak_painter) on X.jfif, invalid shape: (128, 128)\n",
      "Skipping #Pokemon #pixelart #charmander #anime (1).jfif, invalid shape: (128, 128)\n",
      "Skipping #Pokemon #pixelart #charmander #anime.jfif, invalid shape: (128, 128)\n",
      "Skipping 00000000.png, invalid shape: (128, 128)\n",
      "Skipping 00000001.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000002.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000003.png, invalid shape: (128, 128)\n",
      "Skipping 00000004.png, invalid shape: (128, 128)\n",
      "Skipping 00000005.png, invalid shape: (128, 128)\n",
      "Skipping 00000006.png, invalid shape: (128, 128)\n",
      "Skipping 00000007.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000008.png, invalid shape: (128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\DrawEmAll\\lib\\site-packages\\PIL\\Image.py:1056: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 00000009.png, invalid shape: (128, 128)\n",
      "Skipping 00000010.png, invalid shape: (128, 128)\n",
      "Skipping 00000011.png, invalid shape: (128, 128)\n",
      "Skipping 00000012.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000013.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000014.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000015.png, invalid shape: (128, 128)\n",
      "Skipping 00000016.png, invalid shape: (128, 128)\n",
      "Skipping 00000017.png, invalid shape: (128, 128)\n",
      "Skipping 00000018.png, invalid shape: (128, 128)\n",
      "Skipping 00000019.png, invalid shape: (128, 128)\n",
      "Skipping 00000020.png, invalid shape: (128, 128)\n",
      "Skipping 00000021.png, invalid shape: (128, 128)\n",
      "Skipping 00000022.png, invalid shape: (128, 128)\n",
      "Skipping 00000023.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000024.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000025.png, invalid shape: (128, 128)\n",
      "Skipping 00000026.png, invalid shape: (128, 128)\n",
      "Skipping 00000027.png, invalid shape: (128, 128)\n",
      "Skipping 00000028.png, invalid shape: (128, 128)\n",
      "Skipping 00000029.png, invalid shape: (128, 128)\n",
      "Skipping 00000030.png, invalid shape: (128, 128)\n",
      "Skipping 00000031.png, invalid shape: (128, 128)\n",
      "Skipping 00000032.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000033.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000034.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000035.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000036.png, invalid shape: (128, 128)\n",
      "Skipping 00000037.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000038.png, invalid shape: (128, 128)\n",
      "Skipping 00000039.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000040.png, invalid shape: (128, 128)\n",
      "Skipping 00000041.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000042.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000043.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000044.png, invalid shape: (128, 128)\n",
      "Skipping 00000045.png, invalid shape: (128, 128)\n",
      "Skipping 00000046.png, invalid shape: (128, 128)\n",
      "Skipping 00000047.png, invalid shape: (128, 128)\n",
      "Skipping 00000048.png, invalid shape: (128, 128)\n",
      "Skipping 00000049.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000050.png, invalid shape: (128, 128)\n",
      "Skipping 00000051.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000052.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000053.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000054.png, invalid shape: (128, 128)\n",
      "Skipping 00000055.png, invalid shape: (128, 128)\n",
      "Skipping 00000056.png, invalid shape: (128, 128)\n",
      "Skipping 00000057.png, invalid shape: (128, 128)\n",
      "Skipping 00000058.png, invalid shape: (128, 128)\n",
      "Skipping 00000059.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000060.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000061.png, invalid shape: (128, 128)\n",
      "Skipping 00000062.png, invalid shape: (128, 128)\n",
      "Skipping 00000063.png, invalid shape: (128, 128)\n",
      "Skipping 00000064.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000065.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000066.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000067.png, invalid shape: (128, 128)\n",
      "Skipping 00000068.png, invalid shape: (128, 128)\n",
      "Skipping 00000069.png, invalid shape: (128, 128)\n",
      "Skipping 00000070.png, invalid shape: (128, 128)\n",
      "Skipping 00000071.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000072.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000073.png, invalid shape: (128, 128)\n",
      "Skipping 00000074.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000075.png, invalid shape: (128, 128)\n",
      "Skipping 00000076.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000077.png, invalid shape: (128, 128)\n",
      "Skipping 00000078.png, invalid shape: (128, 128)\n",
      "Skipping 00000079.png, invalid shape: (128, 128)\n",
      "Skipping 00000080.png, invalid shape: (128, 128)\n",
      "Skipping 00000081.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000082.png, invalid shape: (128, 128)\n",
      "Skipping 00000083.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000084.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000086.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000087.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000088.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000089.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000090.png, invalid shape: (128, 128)\n",
      "Skipping 00000091.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000092.jpg, invalid shape: (128, 128)\n",
      "Skipping 00000095.png, invalid shape: (128, 128)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mformat_and_label_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m image_date \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32md:\\Learning drawings\\drawEmAll\\CNN_model\\data_fixing.py:37\u001b[0m, in \u001b[0;36mformat_and_label_data\u001b[1;34m(folder_dir, image_size, grayscale)\u001b[0m\n\u001b[0;32m     34\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(starter_folder, filename)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Open the image and resize it to a fixed size \u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#grayscale\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grayscale:\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DrawEmAll\\lib\\site-packages\\PIL\\Image.py:2293\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2290\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreducing_gap must be 1.0 or greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m-> 2293\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m box \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2295\u001b[0m     box \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DrawEmAll\\lib\\site-packages\\PIL\\ImageFile.py:293\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "data = format_and_label_data(grayscale=True)\n",
    "\n",
    "image_date = data[0]\n",
    "labels = data[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image_data, labels, test_size=0.3, random_state=410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">802,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_16 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m802,880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">858,947</span> (3.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m858,947\u001b[0m (3.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">858,883</span> (3.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m858,883\u001b[0m (3.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_CNN_model(dropout=0.45,grayscale=True,image_size=128)\n",
    "\n",
    "model = CNN_fit_train(model, X_train,y_train,X_test,y_test,75,32, './models/best_model_funcbw.keras', datagen = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = load_CNN_model('./models/best_model_func.keras')\n",
    "# acc = CNN_accuracy(model, hand_data, labels)\n",
    "# print(acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "Bulbasaur\n"
     ]
    }
   ],
   "source": [
    "img = format_image(image_path = '../images/Hand_Drawn/Bulbasaur/bulb_color.png', grayscale = False, image_size = 128)\n",
    "print(img.shape)\n",
    "print(CNN_one_pred(model, img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DrawEmAll",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
