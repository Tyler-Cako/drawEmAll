{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize and greyscale images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 00000114.png, invalid shape: (128, 128)\n",
      "Skipping 00000190.png, invalid shape: (128, 128)\n",
      "Skipping 00000009.png, invalid shape: (128, 128)\n",
      "Skipping 00000021.png, invalid shape: (128, 128)\n",
      "Skipping 00000061.png, invalid shape: (128, 128)\n",
      "Skipping 00000078.png, invalid shape: (128, 128)\n",
      "Skipping 00000172.png, invalid shape: (128, 128)\n",
      "Skipping 59bef3942b6041b3a6e0526100264536.jpg, invalid shape: (128, 128)\n"
     ]
    }
   ],
   "source": [
    "image_directory = '../images/dataset'\n",
    "starters = [\"Bulbasaur\", \"Charmander\", \"Squirtle\"]\n",
    "\n",
    "image_data = []\n",
    "labels = []\n",
    "\n",
    "pokemon_to_feature_num = {\n",
    "    \"Bulbasaur\": 0,\n",
    "    \"Charmander\": 1,\n",
    "    \"Squirtle\": 2,\n",
    "\n",
    "}\n",
    "\n",
    "for starter in starters:\n",
    "    starter_folder = os.path.join(image_directory, starter)\n",
    "    \n",
    "    # Make sure the folder exists\n",
    "    if os.path.isdir(starter_folder):\n",
    "        for filename in os.listdir(starter_folder):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith('.jfif'):\n",
    "                image_path = os.path.join(starter_folder, filename)\n",
    "                \n",
    "                # Open the image and resize it to a fixed size \n",
    "                img = Image.open(image_path).resize((128, 128))\n",
    "                #Greyscale\n",
    "                # img = img.convert('L')\n",
    "                # Convert to RGB if it's RGBA\n",
    "                if img.mode == 'RGBA':\n",
    "                    img = img.convert('RGB')  # Discard the alpha channel\n",
    "                img_array = np.array(img)\n",
    "                \n",
    "                if img_array.shape != (128, 128, 3):\n",
    "                    print(f\"Skipping {filename}, invalid shape: {img_array.shape}\")\n",
    "                    continue\n",
    "                else:\n",
    "                    image_data.append(img_array)\n",
    "                    labels.append(pokemon_to_feature_num[starter])\n",
    "\n",
    "labels = np.array(labels)\n",
    "image_data = np.array(image_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the image in greyscale to check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image_data[0].reshape(128, 128,3)\n",
    "img_pillow = Image.fromarray(img)\n",
    "img_pillow.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(847, 128, 128, 3)\n",
      "(847,)\n"
     ]
    }
   ],
   "source": [
    "print(image_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image_data, labels, test_size=0.3, random_state=420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\DrawEmAll\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(layers.BatchNormalization()) # does something good, maybe i'll read more about it but i just added it and it helped a lot\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())#1d for neural network\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.45)) #address overfitting\n",
    "model.add(layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">802,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_27 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_28 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_29 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m802,880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">859,523</span> (3.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m859,523\u001b[0m (3.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">859,459</span> (3.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m859,459\u001b[0m (3.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.4551 - loss: 2.8015\n",
      "Epoch 1: val_accuracy improved from -inf to 0.94118, saving model to ./models/best_model1.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 256ms/step - accuracy: 0.4621 - loss: 2.7462 - val_accuracy: 0.9412 - val_loss: 0.2272\n",
      "Epoch 2/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.8945 - loss: 0.3147\n",
      "Epoch 2: val_accuracy did not improve from 0.94118\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 255ms/step - accuracy: 0.8948 - loss: 0.3138 - val_accuracy: 0.8706 - val_loss: 0.6548\n",
      "Epoch 3/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9218 - loss: 0.2063\n",
      "Epoch 3: val_accuracy did not improve from 0.94118\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 245ms/step - accuracy: 0.9221 - loss: 0.2061 - val_accuracy: 0.8118 - val_loss: 0.7888\n",
      "Epoch 4/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9437 - loss: 0.1632\n",
      "Epoch 4: val_accuracy did not improve from 0.94118\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 275ms/step - accuracy: 0.9445 - loss: 0.1613 - val_accuracy: 0.9333 - val_loss: 0.2609\n",
      "Epoch 5/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9795 - loss: 0.0640\n",
      "Epoch 5: val_accuracy improved from 0.94118 to 0.96471, saving model to ./models/best_model1.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 273ms/step - accuracy: 0.9792 - loss: 0.0651 - val_accuracy: 0.9647 - val_loss: 0.1756\n",
      "Epoch 6/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.9658 - loss: 0.1058\n",
      "Epoch 6: val_accuracy did not improve from 0.96471\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 243ms/step - accuracy: 0.9659 - loss: 0.1050 - val_accuracy: 0.9569 - val_loss: 0.1477\n",
      "Epoch 7/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.9803 - loss: 0.0695\n",
      "Epoch 7: val_accuracy did not improve from 0.96471\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 236ms/step - accuracy: 0.9805 - loss: 0.0693 - val_accuracy: 0.9608 - val_loss: 0.1287\n",
      "Epoch 8/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.9722 - loss: 0.0835\n",
      "Epoch 8: val_accuracy did not improve from 0.96471\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 234ms/step - accuracy: 0.9722 - loss: 0.0831 - val_accuracy: 0.9608 - val_loss: 0.1065\n",
      "Epoch 9/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9788 - loss: 0.1158\n",
      "Epoch 9: val_accuracy did not improve from 0.96471\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 236ms/step - accuracy: 0.9789 - loss: 0.1148 - val_accuracy: 0.9373 - val_loss: 0.2181\n",
      "Epoch 10/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9740 - loss: 0.0592\n",
      "Epoch 10: val_accuracy did not improve from 0.96471\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 259ms/step - accuracy: 0.9738 - loss: 0.0600 - val_accuracy: 0.9569 - val_loss: 0.1531\n",
      "Epoch 11/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9920 - loss: 0.0456\n",
      "Epoch 11: val_accuracy did not improve from 0.96471\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 245ms/step - accuracy: 0.9921 - loss: 0.0452 - val_accuracy: 0.9490 - val_loss: 0.1938\n",
      "Epoch 12/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9774 - loss: 0.0669\n",
      "Epoch 12: val_accuracy did not improve from 0.96471\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 246ms/step - accuracy: 0.9776 - loss: 0.0666 - val_accuracy: 0.9608 - val_loss: 0.1523\n",
      "Epoch 13/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9768 - loss: 0.0662\n",
      "Epoch 13: val_accuracy improved from 0.96471 to 0.96863, saving model to ./models/best_model1.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 246ms/step - accuracy: 0.9769 - loss: 0.0658 - val_accuracy: 0.9686 - val_loss: 0.1406\n",
      "Epoch 14/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9883 - loss: 0.0330\n",
      "Epoch 14: val_accuracy did not improve from 0.96863\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 279ms/step - accuracy: 0.9882 - loss: 0.0328 - val_accuracy: 0.9373 - val_loss: 0.2709\n",
      "Epoch 15/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9902 - loss: 0.0367\n",
      "Epoch 15: val_accuracy did not improve from 0.96863\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 265ms/step - accuracy: 0.9903 - loss: 0.0366 - val_accuracy: 0.9686 - val_loss: 0.1674\n",
      "Epoch 16/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9905 - loss: 0.0243\n",
      "Epoch 16: val_accuracy did not improve from 0.96863\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 260ms/step - accuracy: 0.9906 - loss: 0.0243 - val_accuracy: 0.9608 - val_loss: 0.2221\n",
      "Epoch 17/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.9830 - loss: 0.0477\n",
      "Epoch 17: val_accuracy did not improve from 0.96863\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 269ms/step - accuracy: 0.9830 - loss: 0.0480 - val_accuracy: 0.9451 - val_loss: 0.2838\n",
      "Epoch 18/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9859 - loss: 0.0371\n",
      "Epoch 18: val_accuracy did not improve from 0.96863\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 258ms/step - accuracy: 0.9857 - loss: 0.0379 - val_accuracy: 0.8902 - val_loss: 0.4490\n",
      "Epoch 19/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9772 - loss: 0.0719\n",
      "Epoch 19: val_accuracy did not improve from 0.96863\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 254ms/step - accuracy: 0.9774 - loss: 0.0712 - val_accuracy: 0.9686 - val_loss: 0.1652\n",
      "Epoch 20/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9844 - loss: 0.0608\n",
      "Epoch 20: val_accuracy did not improve from 0.96863\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 258ms/step - accuracy: 0.9843 - loss: 0.0626 - val_accuracy: 0.9647 - val_loss: 0.2653\n",
      "Epoch 21/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9850 - loss: 0.0544\n",
      "Epoch 21: val_accuracy did not improve from 0.96863\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 249ms/step - accuracy: 0.9848 - loss: 0.0548 - val_accuracy: 0.9569 - val_loss: 0.2020\n",
      "Epoch 22/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9831 - loss: 0.0573\n",
      "Epoch 22: val_accuracy improved from 0.96863 to 0.97255, saving model to ./models/best_model1.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 260ms/step - accuracy: 0.9830 - loss: 0.0572 - val_accuracy: 0.9725 - val_loss: 0.1609\n",
      "Epoch 23/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9894 - loss: 0.0294\n",
      "Epoch 23: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 248ms/step - accuracy: 0.9894 - loss: 0.0292 - val_accuracy: 0.9686 - val_loss: 0.1684\n",
      "Epoch 24/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9850 - loss: 0.0340\n",
      "Epoch 24: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 257ms/step - accuracy: 0.9852 - loss: 0.0338 - val_accuracy: 0.9647 - val_loss: 0.2062\n",
      "Epoch 25/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9900 - loss: 0.0160\n",
      "Epoch 25: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 252ms/step - accuracy: 0.9898 - loss: 0.0163 - val_accuracy: 0.9725 - val_loss: 0.2260\n",
      "Epoch 26/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9994 - loss: 0.0080\n",
      "Epoch 26: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 255ms/step - accuracy: 0.9993 - loss: 0.0082 - val_accuracy: 0.9686 - val_loss: 0.2447\n",
      "Epoch 27/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 27: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 255ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9686 - val_loss: 0.2455\n",
      "Epoch 28/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9969 - loss: 0.0057\n",
      "Epoch 28: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 260ms/step - accuracy: 0.9969 - loss: 0.0058 - val_accuracy: 0.9686 - val_loss: 0.2717\n",
      "Epoch 29/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9990 - loss: 0.0102\n",
      "Epoch 29: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 258ms/step - accuracy: 0.9989 - loss: 0.0101 - val_accuracy: 0.9647 - val_loss: 0.3283\n",
      "Epoch 30/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9869 - loss: 0.0549\n",
      "Epoch 30: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 268ms/step - accuracy: 0.9871 - loss: 0.0537 - val_accuracy: 0.9647 - val_loss: 0.4903\n",
      "Epoch 31/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9928 - loss: 0.0281\n",
      "Epoch 31: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 245ms/step - accuracy: 0.9930 - loss: 0.0276 - val_accuracy: 0.9647 - val_loss: 0.2441\n",
      "Epoch 32/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9976 - loss: 0.0096\n",
      "Epoch 32: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 251ms/step - accuracy: 0.9976 - loss: 0.0095 - val_accuracy: 0.9725 - val_loss: 0.3437\n",
      "Epoch 33/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 33: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9725 - val_loss: 0.4176\n",
      "Epoch 34/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.9988 - loss: 0.0096\n",
      "Epoch 34: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 251ms/step - accuracy: 0.9987 - loss: 0.0105 - val_accuracy: 0.9725 - val_loss: 0.4287\n",
      "Epoch 35/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.9829 - loss: 0.0493\n",
      "Epoch 35: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 251ms/step - accuracy: 0.9832 - loss: 0.0485 - val_accuracy: 0.9686 - val_loss: 0.4545\n",
      "Epoch 36/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9933 - loss: 0.0154\n",
      "Epoch 36: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 253ms/step - accuracy: 0.9933 - loss: 0.0154 - val_accuracy: 0.9725 - val_loss: 0.4022\n",
      "Epoch 37/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9990 - loss: 0.0070\n",
      "Epoch 37: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 254ms/step - accuracy: 0.9989 - loss: 0.0071 - val_accuracy: 0.9647 - val_loss: 0.3680\n",
      "Epoch 38/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9886 - loss: 0.0348\n",
      "Epoch 38: val_accuracy improved from 0.97255 to 0.97647, saving model to ./models/best_model1.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 259ms/step - accuracy: 0.9888 - loss: 0.0347 - val_accuracy: 0.9765 - val_loss: 0.5838\n",
      "Epoch 39/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9904 - loss: 0.0396\n",
      "Epoch 39: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 261ms/step - accuracy: 0.9896 - loss: 0.0419 - val_accuracy: 0.9569 - val_loss: 0.4365\n",
      "Epoch 40/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.9885 - loss: 0.0240\n",
      "Epoch 40: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 253ms/step - accuracy: 0.9885 - loss: 0.0241 - val_accuracy: 0.9608 - val_loss: 0.4345\n",
      "Epoch 41/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9948 - loss: 0.0156\n",
      "Epoch 41: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 261ms/step - accuracy: 0.9947 - loss: 0.0158 - val_accuracy: 0.9765 - val_loss: 0.3583\n",
      "Epoch 42/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9890 - loss: 0.0280\n",
      "Epoch 42: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 249ms/step - accuracy: 0.9893 - loss: 0.0277 - val_accuracy: 0.9765 - val_loss: 0.4665\n",
      "Epoch 43/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9952 - loss: 0.0419\n",
      "Epoch 43: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 263ms/step - accuracy: 0.9951 - loss: 0.0429 - val_accuracy: 0.8863 - val_loss: 0.7366\n",
      "Epoch 44/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9800 - loss: 0.0654\n",
      "Epoch 44: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 274ms/step - accuracy: 0.9800 - loss: 0.0653 - val_accuracy: 0.9451 - val_loss: 0.2243\n",
      "Epoch 45/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9940 - loss: 0.0285\n",
      "Epoch 45: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 260ms/step - accuracy: 0.9940 - loss: 0.0286 - val_accuracy: 0.9529 - val_loss: 0.2457\n",
      "Epoch 46/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9962 - loss: 0.0153\n",
      "Epoch 46: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 259ms/step - accuracy: 0.9961 - loss: 0.0152 - val_accuracy: 0.9608 - val_loss: 0.2379\n",
      "Epoch 47/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9841 - loss: 0.0303\n",
      "Epoch 47: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 262ms/step - accuracy: 0.9844 - loss: 0.0304 - val_accuracy: 0.9725 - val_loss: 0.2451\n",
      "Epoch 48/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.9960 - loss: 0.0165\n",
      "Epoch 48: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 272ms/step - accuracy: 0.9961 - loss: 0.0163 - val_accuracy: 0.9686 - val_loss: 0.2575\n",
      "Epoch 49/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9986 - loss: 0.0078\n",
      "Epoch 49: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 276ms/step - accuracy: 0.9984 - loss: 0.0080 - val_accuracy: 0.9725 - val_loss: 0.3019\n",
      "Epoch 50/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.9851 - loss: 0.0724\n",
      "Epoch 50: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 271ms/step - accuracy: 0.9847 - loss: 0.0730 - val_accuracy: 0.8824 - val_loss: 0.6637\n",
      "Epoch 51/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9798 - loss: 0.0610\n",
      "Epoch 51: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 279ms/step - accuracy: 0.9798 - loss: 0.0605 - val_accuracy: 0.9608 - val_loss: 0.3206\n",
      "Epoch 52/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9921 - loss: 0.0161\n",
      "Epoch 52: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 283ms/step - accuracy: 0.9923 - loss: 0.0158 - val_accuracy: 0.9686 - val_loss: 0.3097\n",
      "Epoch 53/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 53: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 272ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9686 - val_loss: 0.3374\n",
      "Epoch 54/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9995 - loss: 0.0054\n",
      "Epoch 54: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 262ms/step - accuracy: 0.9994 - loss: 0.0055 - val_accuracy: 0.9686 - val_loss: 0.3153\n",
      "Epoch 55/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9980 - loss: 0.0057\n",
      "Epoch 55: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 267ms/step - accuracy: 0.9979 - loss: 0.0059 - val_accuracy: 0.9686 - val_loss: 0.3302\n",
      "Epoch 56/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.9976 - loss: 0.0093\n",
      "Epoch 56: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 273ms/step - accuracy: 0.9976 - loss: 0.0093 - val_accuracy: 0.9686 - val_loss: 0.3543\n",
      "Epoch 57/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9983 - loss: 0.0138\n",
      "Epoch 57: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 261ms/step - accuracy: 0.9980 - loss: 0.0149 - val_accuracy: 0.9725 - val_loss: 0.4206\n",
      "Epoch 58/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9929 - loss: 0.0229\n",
      "Epoch 58: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 270ms/step - accuracy: 0.9927 - loss: 0.0235 - val_accuracy: 0.9529 - val_loss: 0.4468\n",
      "Epoch 59/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9897 - loss: 0.0175\n",
      "Epoch 59: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 254ms/step - accuracy: 0.9897 - loss: 0.0178 - val_accuracy: 0.9686 - val_loss: 0.4272\n",
      "Epoch 60/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9863 - loss: 0.0663\n",
      "Epoch 60: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 273ms/step - accuracy: 0.9861 - loss: 0.0676 - val_accuracy: 0.8549 - val_loss: 0.8867\n",
      "Epoch 61/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9938 - loss: 0.0233\n",
      "Epoch 61: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 274ms/step - accuracy: 0.9936 - loss: 0.0234 - val_accuracy: 0.9490 - val_loss: 0.7524\n",
      "Epoch 62/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9940 - loss: 0.0138\n",
      "Epoch 62: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 262ms/step - accuracy: 0.9940 - loss: 0.0138 - val_accuracy: 0.9294 - val_loss: 0.7410\n",
      "Epoch 63/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9939 - loss: 0.0453\n",
      "Epoch 63: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 272ms/step - accuracy: 0.9940 - loss: 0.0443 - val_accuracy: 0.9529 - val_loss: 0.4843\n",
      "Epoch 64/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9966 - loss: 0.0123\n",
      "Epoch 64: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 280ms/step - accuracy: 0.9967 - loss: 0.0120 - val_accuracy: 0.9608 - val_loss: 0.4555\n",
      "Epoch 65/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 65: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 290ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9608 - val_loss: 0.4198\n",
      "Epoch 66/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 66: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 267ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9686 - val_loss: 0.3739\n",
      "Epoch 67/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 67: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9725 - val_loss: 0.3444\n",
      "Epoch 68/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 68: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 280ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9725 - val_loss: 0.3686\n",
      "Epoch 69/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 69: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 285ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9725 - val_loss: 0.3919\n",
      "Epoch 70/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 70: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 294ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9725 - val_loss: 0.4119\n",
      "Epoch 71/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9921 - loss: 0.0102\n",
      "Epoch 71: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 249ms/step - accuracy: 0.9922 - loss: 0.0101 - val_accuracy: 0.9765 - val_loss: 0.4025\n",
      "Epoch 72/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9995 - loss: 0.0028\n",
      "Epoch 72: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 268ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.9765 - val_loss: 0.4069\n",
      "Epoch 73/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9979 - loss: 0.0064\n",
      "Epoch 73: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 275ms/step - accuracy: 0.9979 - loss: 0.0064 - val_accuracy: 0.9725 - val_loss: 0.4856\n",
      "Epoch 74/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9939 - loss: 0.0068\n",
      "Epoch 74: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 254ms/step - accuracy: 0.9939 - loss: 0.0068 - val_accuracy: 0.9725 - val_loss: 0.3474\n",
      "Epoch 75/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 75: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 264ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9765 - val_loss: 0.3368\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint('./models/best_model1.keras', \n",
    "                             monitor='val_accuracy',    # Monitor validation accuracy\n",
    "                             save_best_only=True,       # Save only the best weights\n",
    "                             mode='max',                # 'max' means we want to maximize the metric\n",
    "                             verbose=1)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=75, \n",
    "                    batch_size=32, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks= [checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test on hand drawn images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model1 = tf.keras.models.load_model('./models/best_model1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_image_directory = '../images/Hand_Drawn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hand_data = []\n",
    "if os.path.isdir(hand_image_directory):\n",
    "    for filename in os.listdir(hand_image_directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith('.jfif'):\n",
    "            image_path = os.path.join(hand_image_directory, filename)\n",
    "            \n",
    "            # Open the image and resize it to a fixed size \n",
    "            img = Image.open(image_path).resize((128, 128))\n",
    "            #Greyscale\n",
    "            # img = img.convert('L')\n",
    "            # Convert to RGB if it's RGBA\n",
    "            if img.mode == 'RGBA':\n",
    "                img = img.convert('RGB')  # Discard the alpha channel\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            if img_array.shape != (128, 128, 3):\n",
    "                print(f\"Skipping {filename}, invalid shape: {img_array.shape}\")\n",
    "                continue\n",
    "            else:\n",
    "                hand_data.append(img_array)\n",
    "\n",
    "hand_data = np.array(hand_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = hand_data[0].reshape(128,128 ,3)\n",
    "img_pillow = Image.fromarray(img)\n",
    "img_pillow.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025D9F494040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "[[9.70129073e-01 8.59306137e-09 2.98709366e-02]\n",
      " [1.89236354e-03 2.81807110e-02 9.69926953e-01]\n",
      " [9.90366101e-01 6.27431832e-03 3.35956179e-03]\n",
      " [3.75651420e-12 9.99999762e-01 2.06540548e-07]\n",
      " [9.65103880e-03 3.24806981e-02 9.57868278e-01]\n",
      " [4.67707898e-04 1.52060045e-02 9.84326303e-01]\n",
      " [3.71285724e-10 8.13499014e-07 9.99999166e-01]]\n",
      "[0 2 0 1 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "pred_probs = best_model1.predict(hand_data)\n",
    "print(pred_probs)\n",
    "predicted_class = np.argmax(pred_probs, axis=1)\n",
    "print(predicted_class) # i manually compared by looking in folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 30 epochs for all the colored ones to be guessed correctly..., non colored defaults to squirtle\n",
    "\n",
    "Ok lets see what happens with transformations on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#datagen is interesting\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,              # Randomly rotate images by up to x degrees\n",
    "    width_shift_range=0.2,          # Randomly shift images horizontally by x%\n",
    "    height_shift_range=0.2,         # Randomly shift images vertically by x%\n",
    "    shear_range=0.2,                # Apply shear transformations\n",
    "    zoom_range=0.2,                 # Random zoom\n",
    "    horizontal_flip=True,           # Randomly flip images horizontally\n",
    "    fill_mode='nearest'             # Strategy for filling in missing pixels (due to rotation or shift)\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\DrawEmAll\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model2.add(layers.Flatten())\n",
    "\n",
    "model2.add(layers.Dense(64, activation='relu'))\n",
    "model2.add(layers.Dropout(0.45)) #address overfitting\n",
    "model2.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\DrawEmAll\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.3692 - loss: 4.3132\n",
      "Epoch 1: val_accuracy improved from -inf to 0.80392, saving model to ./models/best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 361ms/step - accuracy: 0.3752 - loss: 4.2109 - val_accuracy: 0.8039 - val_loss: 0.4500\n",
      "Epoch 2/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.7332 - loss: 0.5517\n",
      "Epoch 2: val_accuracy did not improve from 0.80392\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 321ms/step - accuracy: 0.7363 - loss: 0.5486 - val_accuracy: 0.6588 - val_loss: 0.8222\n",
      "Epoch 3/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.9011 - loss: 0.3474\n",
      "Epoch 3: val_accuracy did not improve from 0.80392\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 307ms/step - accuracy: 0.9014 - loss: 0.3461 - val_accuracy: 0.7294 - val_loss: 1.7229\n",
      "Epoch 4/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.8725 - loss: 0.3858\n",
      "Epoch 4: val_accuracy did not improve from 0.80392\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.8727 - loss: 0.3868 - val_accuracy: 0.6863 - val_loss: 0.7359\n",
      "Epoch 5/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.9125 - loss: 0.2804\n",
      "Epoch 5: val_accuracy improved from 0.80392 to 0.94902, saving model to ./models/best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 322ms/step - accuracy: 0.9128 - loss: 0.2798 - val_accuracy: 0.9490 - val_loss: 0.1753\n",
      "Epoch 6/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.9252 - loss: 0.3006\n",
      "Epoch 6: val_accuracy improved from 0.94902 to 0.95294, saving model to ./models/best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 431ms/step - accuracy: 0.9254 - loss: 0.2997 - val_accuracy: 0.9529 - val_loss: 0.1407\n",
      "Epoch 7/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.9384 - loss: 0.2000\n",
      "Epoch 7: val_accuracy did not improve from 0.95294\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 386ms/step - accuracy: 0.9381 - loss: 0.2011 - val_accuracy: 0.9490 - val_loss: 0.1839\n",
      "Epoch 8/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.9309 - loss: 0.2001\n",
      "Epoch 8: val_accuracy did not improve from 0.95294\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 0.9304 - loss: 0.2007 - val_accuracy: 0.9490 - val_loss: 0.2097\n",
      "Epoch 9/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.9230 - loss: 0.2396\n",
      "Epoch 9: val_accuracy improved from 0.95294 to 0.97255, saving model to ./models/best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 387ms/step - accuracy: 0.9225 - loss: 0.2402 - val_accuracy: 0.9725 - val_loss: 0.1425\n",
      "Epoch 10/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.9568 - loss: 0.1439\n",
      "Epoch 10: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 388ms/step - accuracy: 0.9568 - loss: 0.1437 - val_accuracy: 0.9529 - val_loss: 0.2221\n",
      "Epoch 11/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9136 - loss: 0.2326\n",
      "Epoch 11: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 318ms/step - accuracy: 0.9137 - loss: 0.2329 - val_accuracy: 0.9412 - val_loss: 0.1784\n",
      "Epoch 12/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.9333 - loss: 0.1871\n",
      "Epoch 12: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 314ms/step - accuracy: 0.9337 - loss: 0.1872 - val_accuracy: 0.9647 - val_loss: 0.1870\n",
      "Epoch 13/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.9392 - loss: 0.3051\n",
      "Epoch 13: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 309ms/step - accuracy: 0.9396 - loss: 0.3013 - val_accuracy: 0.9686 - val_loss: 0.1558\n",
      "Epoch 14/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9580 - loss: 0.1444\n",
      "Epoch 14: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 309ms/step - accuracy: 0.9582 - loss: 0.1437 - val_accuracy: 0.9608 - val_loss: 0.1860\n",
      "Epoch 15/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.9596 - loss: 0.1001\n",
      "Epoch 15: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 315ms/step - accuracy: 0.9595 - loss: 0.1016 - val_accuracy: 0.9686 - val_loss: 0.1150\n",
      "Epoch 16/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.9550 - loss: 0.1396\n",
      "Epoch 16: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 309ms/step - accuracy: 0.9545 - loss: 0.1415 - val_accuracy: 0.9451 - val_loss: 0.1585\n",
      "Epoch 17/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.9410 - loss: 0.1543\n",
      "Epoch 17: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 308ms/step - accuracy: 0.9410 - loss: 0.1546 - val_accuracy: 0.9569 - val_loss: 0.2696\n",
      "Epoch 18/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.9556 - loss: 0.1311\n",
      "Epoch 18: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - accuracy: 0.9556 - loss: 0.1320 - val_accuracy: 0.9647 - val_loss: 0.1984\n",
      "Epoch 19/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.9525 - loss: 0.1472\n",
      "Epoch 19: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 304ms/step - accuracy: 0.9525 - loss: 0.1474 - val_accuracy: 0.9608 - val_loss: 0.1215\n",
      "Epoch 20/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.9691 - loss: 0.1035\n",
      "Epoch 20: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.9686 - loss: 0.1043 - val_accuracy: 0.9647 - val_loss: 0.1369\n",
      "Epoch 21/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.9595 - loss: 0.0997\n",
      "Epoch 21: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 307ms/step - accuracy: 0.9589 - loss: 0.1013 - val_accuracy: 0.9294 - val_loss: 0.2996\n",
      "Epoch 22/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.9630 - loss: 0.1134\n",
      "Epoch 22: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.9628 - loss: 0.1149 - val_accuracy: 0.9725 - val_loss: 0.1116\n",
      "Epoch 23/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.9660 - loss: 0.1652\n",
      "Epoch 23: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 316ms/step - accuracy: 0.9656 - loss: 0.1641 - val_accuracy: 0.9647 - val_loss: 0.1406\n",
      "Epoch 24/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.9499 - loss: 0.1100\n",
      "Epoch 24: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9508 - loss: 0.1096 - val_accuracy: 0.9725 - val_loss: 0.2270\n",
      "Epoch 25/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.9794 - loss: 0.0757\n",
      "Epoch 25: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 318ms/step - accuracy: 0.9794 - loss: 0.0763 - val_accuracy: 0.9725 - val_loss: 0.0933\n",
      "Epoch 26/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.9610 - loss: 0.1273\n",
      "Epoch 26: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 321ms/step - accuracy: 0.9605 - loss: 0.1282 - val_accuracy: 0.9333 - val_loss: 0.1846\n",
      "Epoch 27/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.9390 - loss: 0.2609\n",
      "Epoch 27: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 321ms/step - accuracy: 0.9397 - loss: 0.2568 - val_accuracy: 0.9608 - val_loss: 0.1836\n",
      "Epoch 28/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.9573 - loss: 0.1644\n",
      "Epoch 28: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.9569 - loss: 0.1663 - val_accuracy: 0.9255 - val_loss: 0.2012\n",
      "Epoch 29/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.9357 - loss: 0.1874\n",
      "Epoch 29: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 315ms/step - accuracy: 0.9363 - loss: 0.1852 - val_accuracy: 0.9647 - val_loss: 0.1839\n",
      "Epoch 30/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.9659 - loss: 0.1078\n",
      "Epoch 30: val_accuracy did not improve from 0.97255\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 317ms/step - accuracy: 0.9661 - loss: 0.1077 - val_accuracy: 0.9686 - val_loss: 0.3072\n",
      "Epoch 31/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9659 - loss: 0.1084\n",
      "Epoch 31: val_accuracy improved from 0.97255 to 0.97647, saving model to ./models/best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 311ms/step - accuracy: 0.9660 - loss: 0.1097 - val_accuracy: 0.9765 - val_loss: 0.1494\n",
      "Epoch 32/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9674 - loss: 0.1040\n",
      "Epoch 32: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 331ms/step - accuracy: 0.9672 - loss: 0.1047 - val_accuracy: 0.9725 - val_loss: 0.1262\n",
      "Epoch 33/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.9642 - loss: 0.1191\n",
      "Epoch 33: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 315ms/step - accuracy: 0.9643 - loss: 0.1181 - val_accuracy: 0.9529 - val_loss: 0.2012\n",
      "Epoch 34/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.9561 - loss: 0.1344\n",
      "Epoch 34: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 316ms/step - accuracy: 0.9567 - loss: 0.1335 - val_accuracy: 0.9647 - val_loss: 0.1814\n",
      "Epoch 35/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.9762 - loss: 0.0849\n",
      "Epoch 35: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - accuracy: 0.9763 - loss: 0.0848 - val_accuracy: 0.9686 - val_loss: 0.1198\n",
      "Epoch 36/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.9612 - loss: 0.1063\n",
      "Epoch 36: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 305ms/step - accuracy: 0.9612 - loss: 0.1069 - val_accuracy: 0.9137 - val_loss: 0.2117\n",
      "Epoch 37/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9749 - loss: 0.1111\n",
      "Epoch 37: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 306ms/step - accuracy: 0.9753 - loss: 0.1095 - val_accuracy: 0.9765 - val_loss: 0.1142\n",
      "Epoch 38/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.9593 - loss: 0.1266\n",
      "Epoch 38: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9594 - loss: 0.1256 - val_accuracy: 0.9255 - val_loss: 0.2307\n",
      "Epoch 39/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.9503 - loss: 0.2365\n",
      "Epoch 39: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - accuracy: 0.9499 - loss: 0.2367 - val_accuracy: 0.8627 - val_loss: 0.3586\n",
      "Epoch 40/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.9216 - loss: 0.2523\n",
      "Epoch 40: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 300ms/step - accuracy: 0.9230 - loss: 0.2487 - val_accuracy: 0.9686 - val_loss: 0.1444\n",
      "Epoch 41/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9604 - loss: 0.1196\n",
      "Epoch 41: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 290ms/step - accuracy: 0.9610 - loss: 0.1182 - val_accuracy: 0.9569 - val_loss: 0.1548\n",
      "Epoch 42/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9814 - loss: 0.0504\n",
      "Epoch 42: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 277ms/step - accuracy: 0.9809 - loss: 0.0517 - val_accuracy: 0.9176 - val_loss: 0.3568\n",
      "Epoch 43/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9702 - loss: 0.0828\n",
      "Epoch 43: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 266ms/step - accuracy: 0.9698 - loss: 0.0840 - val_accuracy: 0.9647 - val_loss: 0.1152\n",
      "Epoch 44/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.9638 - loss: 0.0920\n",
      "Epoch 44: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 268ms/step - accuracy: 0.9637 - loss: 0.0927 - val_accuracy: 0.9137 - val_loss: 0.3000\n",
      "Epoch 45/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9705 - loss: 0.1108\n",
      "Epoch 45: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 269ms/step - accuracy: 0.9704 - loss: 0.1120 - val_accuracy: 0.9373 - val_loss: 0.1573\n",
      "Epoch 46/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9493 - loss: 0.1408\n",
      "Epoch 46: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 268ms/step - accuracy: 0.9488 - loss: 0.1429 - val_accuracy: 0.9569 - val_loss: 0.1866\n",
      "Epoch 47/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9608 - loss: 0.0987\n",
      "Epoch 47: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 268ms/step - accuracy: 0.9611 - loss: 0.0985 - val_accuracy: 0.9569 - val_loss: 0.1057\n",
      "Epoch 48/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9781 - loss: 0.0694\n",
      "Epoch 48: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - accuracy: 0.9775 - loss: 0.0702 - val_accuracy: 0.9647 - val_loss: 0.1375\n",
      "Epoch 49/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9737 - loss: 0.0802\n",
      "Epoch 49: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 277ms/step - accuracy: 0.9736 - loss: 0.0826 - val_accuracy: 0.9294 - val_loss: 0.2143\n",
      "Epoch 50/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9667 - loss: 0.0928\n",
      "Epoch 50: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 262ms/step - accuracy: 0.9661 - loss: 0.0941 - val_accuracy: 0.9373 - val_loss: 0.2138\n",
      "Epoch 51/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.9551 - loss: 0.1026\n",
      "Epoch 51: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 294ms/step - accuracy: 0.9551 - loss: 0.1022 - val_accuracy: 0.9569 - val_loss: 0.1400\n",
      "Epoch 52/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.9845 - loss: 0.0467\n",
      "Epoch 52: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 322ms/step - accuracy: 0.9845 - loss: 0.0467 - val_accuracy: 0.9608 - val_loss: 0.1809\n",
      "Epoch 53/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9850 - loss: 0.0426\n",
      "Epoch 53: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 279ms/step - accuracy: 0.9851 - loss: 0.0426 - val_accuracy: 0.9569 - val_loss: 0.2400\n",
      "Epoch 54/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9756 - loss: 0.0545\n",
      "Epoch 54: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 259ms/step - accuracy: 0.9758 - loss: 0.0542 - val_accuracy: 0.9451 - val_loss: 0.2621\n",
      "Epoch 55/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9731 - loss: 0.0892\n",
      "Epoch 55: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 265ms/step - accuracy: 0.9735 - loss: 0.0887 - val_accuracy: 0.9059 - val_loss: 0.3418\n",
      "Epoch 56/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9830 - loss: 0.0534\n",
      "Epoch 56: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 267ms/step - accuracy: 0.9826 - loss: 0.0536 - val_accuracy: 0.9608 - val_loss: 0.1625\n",
      "Epoch 57/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9793 - loss: 0.0731\n",
      "Epoch 57: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 270ms/step - accuracy: 0.9792 - loss: 0.0732 - val_accuracy: 0.9608 - val_loss: 0.2327\n",
      "Epoch 58/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9792 - loss: 0.0618\n",
      "Epoch 58: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 267ms/step - accuracy: 0.9790 - loss: 0.0624 - val_accuracy: 0.9686 - val_loss: 0.2980\n",
      "Epoch 59/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9993 - loss: 0.0231\n",
      "Epoch 59: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - accuracy: 0.9992 - loss: 0.0234 - val_accuracy: 0.9686 - val_loss: 0.3099\n",
      "Epoch 60/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.9620 - loss: 0.1087\n",
      "Epoch 60: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 271ms/step - accuracy: 0.9623 - loss: 0.1084 - val_accuracy: 0.9725 - val_loss: 0.1817\n",
      "Epoch 61/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9917 - loss: 0.0556\n",
      "Epoch 61: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 269ms/step - accuracy: 0.9915 - loss: 0.0556 - val_accuracy: 0.9608 - val_loss: 0.2691\n",
      "Epoch 62/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9876 - loss: 0.0496\n",
      "Epoch 62: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 275ms/step - accuracy: 0.9875 - loss: 0.0501 - val_accuracy: 0.9686 - val_loss: 0.2659\n",
      "Epoch 63/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.9794 - loss: 0.0777\n",
      "Epoch 63: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - accuracy: 0.9799 - loss: 0.0761 - val_accuracy: 0.9765 - val_loss: 0.1373\n",
      "Epoch 64/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9838 - loss: 0.0531\n",
      "Epoch 64: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 276ms/step - accuracy: 0.9837 - loss: 0.0538 - val_accuracy: 0.9529 - val_loss: 0.2468\n",
      "Epoch 65/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9879 - loss: 0.0643\n",
      "Epoch 65: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 279ms/step - accuracy: 0.9876 - loss: 0.0658 - val_accuracy: 0.9725 - val_loss: 0.1839\n",
      "Epoch 66/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9807 - loss: 0.0907\n",
      "Epoch 66: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 301ms/step - accuracy: 0.9807 - loss: 0.0907 - val_accuracy: 0.9765 - val_loss: 0.1007\n",
      "Epoch 67/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9801 - loss: 0.0507\n",
      "Epoch 67: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 320ms/step - accuracy: 0.9797 - loss: 0.0517 - val_accuracy: 0.9686 - val_loss: 0.2183\n",
      "Epoch 68/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.9883 - loss: 0.0522\n",
      "Epoch 68: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - accuracy: 0.9882 - loss: 0.0528 - val_accuracy: 0.9569 - val_loss: 0.1415\n",
      "Epoch 69/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9815 - loss: 0.0948\n",
      "Epoch 69: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 266ms/step - accuracy: 0.9814 - loss: 0.0958 - val_accuracy: 0.9725 - val_loss: 0.2717\n",
      "Epoch 70/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9817 - loss: 0.0830\n",
      "Epoch 70: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 284ms/step - accuracy: 0.9816 - loss: 0.0835 - val_accuracy: 0.9333 - val_loss: 0.2794\n",
      "Epoch 71/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.9769 - loss: 0.0690\n",
      "Epoch 71: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 304ms/step - accuracy: 0.9766 - loss: 0.0704 - val_accuracy: 0.9608 - val_loss: 0.2200\n",
      "Epoch 72/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.9704 - loss: 0.0693\n",
      "Epoch 72: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 314ms/step - accuracy: 0.9705 - loss: 0.0701 - val_accuracy: 0.9529 - val_loss: 0.1896\n",
      "Epoch 73/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9550 - loss: 0.1824\n",
      "Epoch 73: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 265ms/step - accuracy: 0.9551 - loss: 0.1808 - val_accuracy: 0.9098 - val_loss: 0.4731\n",
      "Epoch 74/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9818 - loss: 0.0699\n",
      "Epoch 74: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 259ms/step - accuracy: 0.9815 - loss: 0.0704 - val_accuracy: 0.9725 - val_loss: 0.1796\n",
      "Epoch 75/75\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9841 - loss: 0.0590\n",
      "Epoch 75: val_accuracy did not improve from 0.97647\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 265ms/step - accuracy: 0.9842 - loss: 0.0588 - val_accuracy: 0.9686 - val_loss: 0.1203\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint('./models/best_model.keras', \n",
    "                             monitor='val_accuracy',    # Monitor validation accuracy\n",
    "                             save_best_only=True,       # Save only the best weights\n",
    "                             mode='max',                # 'max' means we want to maximize the metric\n",
    "                             verbose=1)\n",
    "\n",
    "history = model2.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),  # Augmented images in batches\n",
    "    epochs=75,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9758 - loss: 0.2187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14939461648464203, 0.9764705896377563]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model('./models/best_model.keras')\n",
    "best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025DE4FE9090> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "[[7.0893776e-01 3.7793782e-07 2.9106191e-01]\n",
      " [2.9696652e-01 2.1709745e-01 4.8593605e-01]\n",
      " [5.0650114e-01 7.4308947e-02 4.1918990e-01]\n",
      " [2.2669948e-08 9.9999666e-01 3.3658469e-06]\n",
      " [3.4908891e-01 1.5426618e-01 4.9664494e-01]\n",
      " [4.0449947e-01 1.0927055e-01 4.8622993e-01]\n",
      " [1.9994812e-02 1.1142439e-03 9.7889084e-01]]\n",
      "[0 2 0 1 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "pred_probs = best_model.predict(hand_data)\n",
    "print(pred_probs)\n",
    "predicted_class = np.argmax(pred_probs, axis=1)\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\DrawEmAll\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 275ms/step - accuracy: 0.9607 - loss: 0.0845 - val_accuracy: 0.9647 - val_loss: 0.1666\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 273ms/step - accuracy: 0.9555 - loss: 0.1903 - val_accuracy: 0.9686 - val_loss: 0.1378\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 278ms/step - accuracy: 0.9682 - loss: 0.1020 - val_accuracy: 0.9490 - val_loss: 0.2029\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - accuracy: 0.9621 - loss: 0.1227 - val_accuracy: 0.9451 - val_loss: 0.1976\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 265ms/step - accuracy: 0.9803 - loss: 0.0798 - val_accuracy: 0.9647 - val_loss: 0.1803\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 261ms/step - accuracy: 0.9636 - loss: 0.1044 - val_accuracy: 0.9569 - val_loss: 0.2177\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - accuracy: 0.9660 - loss: 0.0981 - val_accuracy: 0.9569 - val_loss: 0.1809\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 265ms/step - accuracy: 0.9651 - loss: 0.1151 - val_accuracy: 0.9686 - val_loss: 0.1566\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 264ms/step - accuracy: 0.9766 - loss: 0.0625 - val_accuracy: 0.9569 - val_loss: 0.2081\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 270ms/step - accuracy: 0.9674 - loss: 0.0858 - val_accuracy: 0.9529 - val_loss: 0.1362\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 283ms/step - accuracy: 0.9811 - loss: 0.0734 - val_accuracy: 0.9686 - val_loss: 0.1540\n",
      "Epoch 2/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 308ms/step - accuracy: 0.9743 - loss: 0.0501 - val_accuracy: 0.9569 - val_loss: 0.2048\n",
      "Epoch 3/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 278ms/step - accuracy: 0.9817 - loss: 0.0499 - val_accuracy: 0.9647 - val_loss: 0.1880\n",
      "Epoch 4/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 267ms/step - accuracy: 0.9697 - loss: 0.0701 - val_accuracy: 0.9686 - val_loss: 0.2064\n",
      "Epoch 5/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 267ms/step - accuracy: 0.9521 - loss: 0.1426 - val_accuracy: 0.9529 - val_loss: 0.1857\n",
      "Epoch 6/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 260ms/step - accuracy: 0.9725 - loss: 0.0902 - val_accuracy: 0.9333 - val_loss: 0.2710\n",
      "Epoch 7/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 260ms/step - accuracy: 0.9569 - loss: 0.1300 - val_accuracy: 0.9216 - val_loss: 0.2660\n",
      "Epoch 8/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 274ms/step - accuracy: 0.9616 - loss: 0.0917 - val_accuracy: 0.9569 - val_loss: 0.2176\n",
      "Epoch 9/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 273ms/step - accuracy: 0.9786 - loss: 0.0812 - val_accuracy: 0.9686 - val_loss: 0.2123\n",
      "Epoch 10/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 268ms/step - accuracy: 0.9528 - loss: 0.2287 - val_accuracy: 0.9451 - val_loss: 0.2600\n",
      "Epoch 11/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 265ms/step - accuracy: 0.9719 - loss: 0.0869 - val_accuracy: 0.9608 - val_loss: 0.1605\n",
      "Epoch 12/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 281ms/step - accuracy: 0.9945 - loss: 0.0226 - val_accuracy: 0.9647 - val_loss: 0.1712\n",
      "Epoch 13/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 277ms/step - accuracy: 0.9736 - loss: 0.0727 - val_accuracy: 0.9608 - val_loss: 0.1692\n",
      "Epoch 14/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 275ms/step - accuracy: 0.9767 - loss: 0.0648 - val_accuracy: 0.9490 - val_loss: 0.2565\n",
      "Epoch 15/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 267ms/step - accuracy: 0.9762 - loss: 0.0504 - val_accuracy: 0.9686 - val_loss: 0.1929\n",
      "Epoch 16/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 265ms/step - accuracy: 0.9742 - loss: 0.0516 - val_accuracy: 0.9608 - val_loss: 0.1789\n",
      "Epoch 17/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 267ms/step - accuracy: 0.9782 - loss: 0.0838 - val_accuracy: 0.9608 - val_loss: 0.1381\n",
      "Epoch 18/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 276ms/step - accuracy: 0.9798 - loss: 0.0572 - val_accuracy: 0.9608 - val_loss: 0.1530\n",
      "Epoch 19/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 272ms/step - accuracy: 0.9781 - loss: 0.0531 - val_accuracy: 0.9647 - val_loss: 0.2296\n",
      "Epoch 20/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 269ms/step - accuracy: 0.9765 - loss: 0.0690 - val_accuracy: 0.9569 - val_loss: 0.2062\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "[[7.0132680e-02 1.8187502e-06 9.2986554e-01]\n",
      " [3.3418107e-01 3.5123985e-02 6.3069493e-01]\n",
      " [6.5888751e-01 2.0125033e-01 1.3986214e-01]\n",
      " [1.8295322e-07 9.9995494e-01 4.4885808e-05]\n",
      " [3.7500429e-01 1.1292139e-01 5.1207429e-01]\n",
      " [4.0733567e-01 7.6039352e-02 5.1662499e-01]\n",
      " [6.1818344e-07 2.0156102e-10 9.9999940e-01]]\n",
      "[2 2 0 1 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "pred_probs = model2.predict(hand_data)\n",
    "print(pred_probs)\n",
    "predicted_class = np.argmax(pred_probs, axis=1)\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DrawEmAll",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
